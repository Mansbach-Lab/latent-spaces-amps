{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e72f7e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main function called /n\n",
      "train_parser function called /n\n",
      "train function called /n\n",
      "parser model_init called /n\n",
      "VAE_shell init called /n\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "VAE_Shell train called /n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\amp21\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 Train - 2.678554164038764 Val - 2.129689931869507 KLBeta - 1e-08 Epoch time - -25.73671\n",
      "VAE_Shell save called /n\n",
      "Epoch - 2 Train - 1.9402802255418565 Val - 1.9438968406004065 KLBeta - 0.005000009 Epoch time - -25.86365\n",
      "VAE_Shell save called /n\n",
      "Epoch - 3 Train - 1.765068186653985 Val - 1.7933067854712992 KLBeta - 0.010000008 Epoch time - -25.71963\n",
      "VAE_Shell save called /n\n",
      "Epoch - 4 Train - 1.6346927881240845 Val - 1.6799204139148487 KLBeta - 0.015000007 Epoch time - -26.22921\n",
      "VAE_Shell save called /n\n",
      "Epoch - 5 Train - 1.5463555918799505 Val - 1.5938287202049704 KLBeta - 0.020000006 Epoch time - -26.95793\n",
      "VAE_Shell save called /n\n",
      "VAE_Shell save called /n\n",
      "Epoch - 6 Train - 1.4654223256640964 Val - 1.5159211859983557 KLBeta - 0.025000005 Epoch time - -26.34162\n",
      "VAE_Shell save called /n\n",
      "Epoch - 7 Train - 1.3794337511062622 Val - 1.4394288624034208 KLBeta - 0.030000004 Epoch time - -26.40895\n",
      "VAE_Shell save called /n\n",
      "Epoch - 8 Train - 1.3059642050001357 Val - 1.3838983423569624 KLBeta - 0.035000003 Epoch time - -26.52478\n",
      "VAE_Shell save called /n\n",
      "Epoch - 9 Train - 1.2479301028781467 Val - 1.328197857912849 KLBeta - 0.040000002 Epoch time - -26.46042\n",
      "VAE_Shell save called /n\n",
      "Epoch - 10 Train - 1.192575799094306 Val - 1.2806523898068596 KLBeta - 0.045000001 Epoch time - -26.79587\n",
      "VAE_Shell save called /n\n",
      "VAE_Shell save called /n\n"
     ]
    }
   ],
   "source": [
    "%run scripts/train.py --model wae --data_source zinc --epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bef6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train function called /n\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'init_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ecaba9bf088>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\GitHub\\MSCSAM_TBD\\outsourced_models\\vae\\debugging\\scripts\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     32\u001b[0m               \u001b[1;34m'LR_SCALE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m               \u001b[1;34m'WARMUP_STEPS'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m               \u001b[1;34m'INIT_METHOD'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m               \u001b[1;34m'DIST_BACKEND'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist_backend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m               \u001b[1;34m'WORLD_SIZE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Args' object has no attribute 'init_method'"
     ]
    }
   ],
   "source": [
    "from scripts.train import train\n",
    "from transvae import rnn_models\n",
    "from transvae import trans_models\n",
    "\n",
    "\n",
    "class Args():\n",
    "    checkpoint=None\n",
    "    adam_lr=3e-4\n",
    "    anneal_start=0\n",
    "    batch_chunks=5\n",
    "    batch_size=1000\n",
    "    beta=0.05\n",
    "    beta_init=1e-8\n",
    "    eps_scale=1\n",
    "    lr_scale=1\n",
    "    warmup_steps=10000\n",
    "    property_predictor=False\n",
    "    save_name=None\n",
    "    d_model=128\n",
    "    d_latent=128\n",
    "    d_property_predictor=256\n",
    "    depth_property_predictor=2\n",
    "    epochs=2\n",
    "    save_freq=5\n",
    "    model = \"rnn\"\n",
    "    data_source = \"zinc\"\n",
    "\n",
    "args = Args()\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle(\"data\\char_dict_zinc.pkl\") #the dict is just a mapping for each possible smile token to an int\n",
    "weights = np.load(\"data\\char_weights_zinc.npy\") \n",
    "train = pd.read_csv('data\\zinc_complete\\zinc_train.txt').to_numpy()\n",
    "from transvae import tvae_util\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df, weights)\n",
    "\n",
    "print(\"with start and end: \",df)\n",
    "df = {i:df[i] for i in df if i!='<end>'}\n",
    "df = {i:df[i] for i in df if i!='<start>'}\n",
    "print(\"withOUT start and end: \",df)\n",
    "\n",
    "parameters_class = {\"NUM_CHAR\" : 24,  \"CHAR_DICT\" : df, \"MAX_LENGTH\" : 126 } \n",
    "params = parameters_class\n",
    "\n",
    "smiles = []\n",
    "for smile in train:\n",
    "    smiles.append(tvae_util.smi_tokenizer(smile[0]))\n",
    "print(smiles[0])\n",
    "\n",
    "char_weights = tvae_util.get_char_weights(smiles,params)\n",
    "print(char_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pep = pd.read_csv('data/peptides/1_to_50_reviewed_seq_only.fasta').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd242ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspired by the Trans-Vae tokenizer\n",
    "def peptide_tokenizer(peptide):\n",
    "    \"Tokenizes SMILES string\"\n",
    "    #need to remove \"X\", \"B\", \"Z\", \"U\"\n",
    "    pattern =  \"(G|A|L|M|F|W|K|Q|E|S|P|V|I|C|Y|H|R|N|D|T|X|B|Z|U)\"\n",
    "    regezz = re.compile(pattern)\n",
    "    tokens = [token for token in regezz.findall(peptide)]\n",
    "    assert peptide == ''.join(tokens), (\"{} could not be joined\".format(peptide))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "peptides = []\n",
    "for peptide in pep:\n",
    "    peptides.append(peptide_tokenizer(peptide[0]))\n",
    "print(peptides[0], \"longest\", longest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_dict = {\"G\": 1, \"A\":2, \"L\":3,\"M\":4,\"F\":5,\"W\":6,\"K\":7,\"Q\":8,\"E\":9,\"S\":10,\"P\":11,\"V\":12,\"I\":13,\"C\":14,\"Y\":15,\"H\":16,\"R\":17,\"N\":18,\"D\":19,\"T\":20,\"X\":21,\"B\":22,\"Z\":23,\"U\":24}\n",
    "parameters = {\"NUM_CHAR\" : 24,  \"CHAR_DICT\" : pep_dict, \"MAX_LENGTH\" : 50 } \n",
    "\n",
    "\n",
    "char_weights = tvae_util.get_char_weights(peptides,parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transvae\n",
    "import os\n",
    "path = os.path.abspath(transvae.__file__)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4212d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/train.py --model rnn --data_source zinc --DDP True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb4017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
