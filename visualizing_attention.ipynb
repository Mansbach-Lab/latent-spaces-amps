{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE*** - You must have RDKit and tensor2tensor installed to use this tutorial. Documentation/installation instructions for each can be found at [https://www.rdkit.org/docs/GettingStartedInPython.html](https://www.rdkit.org/docs/GettingStartedInPython.html) and [https://github.com/tensorflow/tensor2tensor](https://github.com/tensorflow/tensor2tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ColorConverter\n",
    "\n",
    "from transvae.tvae_util import *\n",
    "\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Draw\n",
    "# from rdkit.Chem.Draw import rdMolDraw2D\n",
    "# from rdkit.Chem import rdDepictor\n",
    "# rdDepictor.SetPreferCoordGen(True)\n",
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG\n",
    "from collections import defaultdict\n",
    "# import rdkit\n",
    "# print(rdkit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.visualization import attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "  paths: {\n",
       "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython.display as Disp\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function\n",
    "# def align_smiles_w_mol(mol, smi):\n",
    "#     atom_chars = ['C', 'c', 'S', 'O', 'o', 'N', 'n', '[nH]', 'Cl', 'Br', 'F']\n",
    "#     smi = ['<bos>'] + tokenizer(smi)\n",
    "#     molidx_2_smidx = {}\n",
    "#     at_names = []\n",
    "#     for at in mol.GetAtoms():\n",
    "#         at_names.append(at.GetSymbol())\n",
    "#     idx_tracker = 0\n",
    "#     for i, char in enumerate(smi):\n",
    "#         if char in atom_chars:\n",
    "#             molidx_2_smidx[i] = idx_tracker\n",
    "#             idx_tracker += 1\n",
    "#     return molidx_2_smidx, at_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Attention\n",
    "\n",
    "Attention weights are unique to each molecular embedding and calculated during inference based on the model parameters learned during training. The `attention.py` script will calculate and save the weights for a trained model on a given set of SMILES strings. Attention weights are stored in a matrix with dimensions `[n_samples, n_layers, n_attention_heads, tok_seq1, tok_seq2]`. The `RNNAttn` models only have 1 layer and 1 attention head. The `Trans` models have 4 attention heads, 4 layers of self-attention and 3 layers of source-attention (connecting the encoder to the decoder). \n",
    "\n",
    "We will use a small set of pre-calculated weights for the `Trans4x-256` model to demonstrate visualizing attention on the first layer in the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Molecule\n",
    "# This code calculates all necessary data for visualization\n",
    "# mol_idx = 4\n",
    "# smi = smiles[mol_idx]\n",
    "# #mol = Chem.MolFromSmiles(smi)\n",
    "# #m_2_s, at_names = align_smiles_w_mol(mol, smi) #this allows us to access specific atoms in RDKit representation\n",
    "# #smi_toks = ['<bos>'] + smi_tokenizer(smi)\n",
    "# smi_label = smi_tokenizer(smi)\n",
    "# src = ['<bos>'] + smi_label\n",
    "# tgt = []\n",
    "# for i, tok in enumerate(src):\n",
    "#     tgt.append('{}_{}'.format(i, tok))\n",
    "# self_wt_ = attn_wts[mol_idx,:,:,:len(src),:len(src)]\n",
    "# self_wts = []\n",
    "# for i in range(self_wt_.shape[0]):\n",
    "#     self_wt = self_wt_[i,:,:,:]\n",
    "#     self_wts.append(self_wt)\n",
    "# mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for visualizing attention is very simple. We pass the source SMILE and the self-attention weights. You must first select input-input or input-output from the attention drop down or else the visualization will be overwhelming. Only layer 0 is active, but we can view individual attention heads (blue, orange, green or red) by selecting or de-selecting them from the check boxes at the top. Mousing over specific tokens will also allow you to see the attention for just those tokens specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 79 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19076/1373519943.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mself_wt_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_wts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmol_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mself_wts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_wt_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 79 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "# Load Weights and SMILES\n",
    "smiles = pd.read_csv('data/peptide_test.txt').to_numpy()[:,0]\n",
    "attn_wts = np.load('data/attn_weights_src_attn.npy')\n",
    "#data\n",
    "mol_idx = 79\n",
    "smi = smiles[mol_idx]\n",
    "smi_label = peptide_tokenizer(smi)\n",
    "#smi_label = tokenizer(smi)\n",
    "src = ['<bos>'] + smi_label\n",
    "tgt = []\n",
    "for i, tok in enumerate(src):\n",
    "    tgt.append('{}_{}'.format(i, tok))\n",
    "#weights\n",
    "self_wt_ = attn_wts[mol_idx,:,:,:len(src),:len(src)]\n",
    "self_wts = []    \n",
    "for i in range(self_wt_.shape[0]):\n",
    "    self_wt = self_wt_[i,:,:,:]\n",
    "    self_wts.append(self_wt) \n",
    "# Visualizing attention\n",
    "attention.show(src, tgt, self_wts, self_wts, self_wts)\n",
    "\n",
    "#colors are the different attention heads\n",
    "#layer is the current layer being shown\n",
    "#iput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the weights between atom tokens directly by using the built in highlighting functionality of RDKits drawing tool. The atoms that are being attended to are colored by the respective attention head color and the atom that is attending to the tokens is colored in black. You may change the attn_head or atom_idx to visualize other relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_2_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6dffccc448fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhit_ats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mm_2_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0msat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm_2_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattn_head\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm_2_s' is not defined"
     ]
    }
   ],
   "source": [
    "attn_head = 0\n",
    "atom_idx = 16\n",
    "atom_wts = self_wts[0][0,attn_head,:,atom_idx]\n",
    "hit_ats = np.where(atom_wts > 1e-5)[0]\n",
    "\n",
    "color_names = ['blue', 'orange', 'green', 'red', 'black']\n",
    "colors = []\n",
    "for name in color_names:\n",
    "    colors.append(ColorConverter().to_rgb(name))\n",
    "athighlights = defaultdict(list)\n",
    "arads = {}\n",
    "for at in hit_ats:\n",
    "    at = int(at)\n",
    "    if at in m_2_s.keys():\n",
    "        sat = m_2_s[at]\n",
    "        color = list(colors[attn_head])\n",
    "        color.append(atom_wts[at])\n",
    "        athighlights[sat].append(colors[attn_head])\n",
    "        arads[sat] = float(atom_wts[at]) / 4\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "at = int(atom_idx)\n",
    "if at in m_2_s.keys():\n",
    "    sat = m_2_s[at]\n",
    "    color = list(colors[-1])\n",
    "    color.append(atom_wts[at])\n",
    "    athighlights[sat].append(colors[-1])\n",
    "    arads[sat] = 0.25\n",
    "\n",
    "d2d = rdMolDraw2D.MolDraw2DSVG(400,400)\n",
    "d2d.DrawMoleculeWithHighlights(mol,'',dict(athighlights),{},arads,{})\n",
    "d2d.FinishDrawing()\n",
    "svg = d2d.GetDrawingText()\n",
    "SVG(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
