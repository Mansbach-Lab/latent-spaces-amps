{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e72f7e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main function called /n\n",
      "train_parser function called /n\n",
      "train function called /n\n",
      "parser model_init called /n\n",
      "rnn-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\amp21\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn-128_peptide\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mG:\\GitHub\\MSCSAM_TBD\\main_model\\scripts\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\GitHub\\MSCSAM_TBD\\main_model\\scripts\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     vae.train(train_mols, test_mols, train_props, test_props,\n\u001b[0m\u001b[0;32m     92\u001b[0m               epochs=args.epochs, save_freq=args.save_freq)\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_mols, val_mols, train_props, val_props, epochs, save, save_freq, log, log_dir)\u001b[0m\n\u001b[0;32m    316\u001b[0m                     \u001b[0mavg_prop_mse_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop_mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'aae'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#the aae backpropagates in the loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'aae'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\amp21\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\envs\\amp21\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run scripts/train.py --model rnn --data_source peptide --epochs 2 --checkpoint checkpointz/010_rnn-128_peptide.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bef6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train function called /n\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'init_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ecaba9bf088>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\GitHub\\MSCSAM_TBD\\outsourced_models\\vae\\debugging\\scripts\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     32\u001b[0m               \u001b[1;34m'LR_SCALE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m               \u001b[1;34m'WARMUP_STEPS'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m               \u001b[1;34m'INIT_METHOD'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m               \u001b[1;34m'DIST_BACKEND'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist_backend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m               \u001b[1;34m'WORLD_SIZE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Args' object has no attribute 'init_method'"
     ]
    }
   ],
   "source": [
    "from scripts.train import train\n",
    "from transvae import rnn_models\n",
    "from transvae import trans_models\n",
    "\n",
    "\n",
    "class Args():\n",
    "    checkpoint=None\n",
    "    adam_lr=3e-4\n",
    "    anneal_start=0\n",
    "    batch_chunks=5\n",
    "    batch_size=1000\n",
    "    beta=0.05\n",
    "    beta_init=1e-8\n",
    "    eps_scale=1\n",
    "    lr_scale=1\n",
    "    warmup_steps=10000\n",
    "    property_predictor=False\n",
    "    save_name=None\n",
    "    d_model=128\n",
    "    d_latent=128\n",
    "    d_property_predictor=256\n",
    "    depth_property_predictor=2\n",
    "    epochs=2\n",
    "    save_freq=5\n",
    "    model = \"rnn\"\n",
    "    data_source = \"zinc\"\n",
    "\n",
    "args = Args()\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3da6e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle(\"data\\custom_char_dict.pkl\") #the dict is just a mapping for each possible smile token to an int\n",
    "weights = np.load(\"data\\custom_char_weights.npy\") \n",
    "train = pd.read_csv('data\\zinc_train.txt').to_numpy()\n",
    "from transvae import tvae_util\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a30d3f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'<start>': 0,\n",
       "  'C': 1,\n",
       "  'S': 2,\n",
       "  '(': 3,\n",
       "  '=': 4,\n",
       "  'O': 5,\n",
       "  ')': 6,\n",
       "  'c': 7,\n",
       "  '1': 8,\n",
       "  '2': 9,\n",
       "  '[nH]': 10,\n",
       "  'N': 11,\n",
       "  'Cl': 12,\n",
       "  'n': 13,\n",
       "  '3': 14,\n",
       "  'F': 15,\n",
       "  '-': 16,\n",
       "  '4': 17,\n",
       "  '#': 18,\n",
       "  'Br': 19,\n",
       "  's': 20,\n",
       "  'o': 21,\n",
       "  '5': 22,\n",
       "  '_': 23,\n",
       "  '<end>': 24},\n",
       " 24,\n",
       " array([0.60821437, 0.77987635, 0.62986889, 0.67002429, 0.64851463,\n",
       "        0.62986889, 0.58027273, 0.63966943, 0.66274048, 0.90019052,\n",
       "        0.68713979, 0.82368183, 0.67710345, 0.7346053 , 0.78505427,\n",
       "        0.80267549, 0.92739044, 0.90820026, 0.96183292, 0.82124607,\n",
       "        0.82710019, 1.        , 0.1       , 0.69595128]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,len(weights),weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b5830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with start and end:  {'C': 1, 'c': 2, '1': 3, '(': 4, ')': 5, 'N': 6, '=': 7, 'S': 8, '2': 9, 'O': 10, '3': 11, 'F': 12, 'n': 13, 's': 14, '-': 15, 'Cl': 16, '4': 17, '5': 18, '6': 19, 'Br': 20, '[nH]': 21, '#': 22, 'o': 23, '_': 24}\n",
      "withOUT start and end:  {'C': 1, 'c': 2, '1': 3, '(': 4, ')': 5, 'N': 6, '=': 7, 'S': 8, '2': 9, 'O': 10, '3': 11, 'F': 12, 'n': 13, 's': 14, '-': 15, 'Cl': 16, '4': 17, '5': 18, '6': 19, 'Br': 20, '[nH]': 21, '#': 22, 'o': 23, '_': 24}\n",
      "['C', 'C', 'C', 'S', '(', '=', 'O', ')', 'c', '1', 'c', 'c', 'c', '2', '[nH]', 'c', '(', '=', 'N', 'C', '(', '=', 'O', ')', 'O', 'C', ')', '[nH]', 'c', '2', 'c', '1']\n"
     ]
    }
   ],
   "source": [
    "#print(df, weights)\n",
    "\n",
    "print(\"with start and end: \",df)\n",
    "df = {i:df[i] for i in df if i!='<end>'}\n",
    "df = {i:df[i] for i in df if i!='<start>'}\n",
    "print(\"withOUT start and end: \",df)\n",
    "\n",
    "parameters_class = {\"NUM_CHAR\" : 24,  \"CHAR_DICT\" : df, \"MAX_LENGTH\" : 126 } \n",
    "params = parameters_class\n",
    "\n",
    "smiles = []\n",
    "for smile in train:\n",
    "    smiles.append(tvae_util.smi_tokenizer(smile[0]))\n",
    "print(smiles[0])\n",
    "\n",
    "#char_weights = tvae_util.get_char_weights(smiles,params)\n",
    "#print(char_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78c94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58110517 0.57052939 0.61378371 0.60573439 0.60573439 0.64060813\n",
      " 0.64227208 0.74804077 0.63342546 0.62599061 0.68947928 0.71699988\n",
      " 0.64437949 0.74999955 0.74609909 0.77399147 0.82480161 1.\n",
      " 1.         0.86431985 0.77698479 0.79953633 0.75471153 0.1\n",
      " 0.75      ]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pep = pd.read_csv('data/peptides/1_to_50_reviewed_seq_only.fasta').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd242ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspired by the Trans-Vae tokenizer\n",
    "def peptide_tokenizer(peptide):\n",
    "    \"Tokenizes SMILES string\"\n",
    "    #need to remove \"X\", \"B\", \"Z\", \"U\"\n",
    "    pattern =  \"(G|A|L|M|F|W|K|Q|E|S|P|V|I|C|Y|H|R|N|D|T|X|B|Z|U)\"\n",
    "    regezz = re.compile(pattern)\n",
    "    tokens = [token for token in regezz.findall(peptide)]\n",
    "    assert peptide == ''.join(tokens), (\"{} could not be joined\".format(peptide))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5d56a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9c509c285c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpeptides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpeptide\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpeptides\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeptide_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeptide\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeptides\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"longest\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pep' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "peptides = []\n",
    "for peptide in pep:\n",
    "    peptides.append(peptide_tokenizer(peptide[0]))\n",
    "print(peptides[0], \"longest\", longest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pep_dict = {\"G\": 1, \"A\":2, \"L\":3,\"M\":4,\"F\":5,\"W\":6,\"K\":7,\"Q\":8,\"E\":9,\"S\":10,\"P\":11,\"V\":12,\"I\":13,\"C\":14,\"Y\":15,\"H\":16,\"R\":17,\"N\":18,\"D\":19,\"T\":20,\"X\":21,\"B\":22,\"Z\":23,\"U\":24}\n",
    "parameters = {\"NUM_CHAR\" : 24,  \"CHAR_DICT\" : pep_dict, \"MAX_LENGTH\" : 50 } \n",
    "\n",
    "\n",
    "char_weights = tvae_util.get_char_weights(peptides,parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfeb4017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building dictionary...\n",
      "calculating weights...\n",
      "{'M': 135075, 'A': 348190, 'I': 278099, 'S': 283329, 'Q': 162650, 'E': 288445, 'K': 408377, 'N': 186291, 'Y': 126937, 'R': 339004, 'H': 101310, 'G': 320141, 'D': 205091, 'T': 240419, 'V': 325558, 'L': 424147, 'F': 181530, 'W': 57602, 'P': 190185, 'C': 156467, '_': 9243503, '<end>': 93349}\n"
     ]
    }
   ],
   "source": [
    "%run scripts/build_vocab.py --inputs data\\peptides\\peptide_train.txt --max_len 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f628785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66075633, 0.6018436 , 0.61068701, 0.60286361, 0.73658086,\n",
       "       0.59539247, 0.65802035, 0.61671083, 0.61097385, 0.6184843 ,\n",
       "       0.65109993, 0.64359417, 0.60415347, 0.64448577, 0.62691629,\n",
       "       0.65689944, 0.63483703, 0.62951292, 0.70116584, 0.66961309,\n",
       "       0.89228125, 1.        , 1.        , 1.        , 0.1       ,\n",
       "       0.6573441 ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.load(\"data\\custom_char_weights.npy\")\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f16cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
