{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e72f7e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main function called /n\n",
      "train_parser function called /n\n",
      "train function called /n\n",
      "parser model_init called /n\n",
      "RNNEncoderDecoder(\n",
      "  (encoder): RNNEncoder(\n",
      "    (gru): GRU(128, 128, num_layers=3, dropout=0.1)\n",
      "    (norm): LayerNorm()\n",
      "    (linear_bypass): Linear(in_features=128, out_features=32, bias=True)\n",
      "  )\n",
      "  (decoder): RNNDecoder(\n",
      "    (gru): GRU(256, 128, num_layers=3, dropout=0.1)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (norm): LayerNorm()\n",
      "    (linear_bypass): Linear(in_features=32, out_features=128, bias=True)\n",
      "  )\n",
      "  (discriminator): Discriminator(\n",
      "    (layers_seq): Sequential(\n",
      "      (linear_0): Linear(in_features=32, out_features=640, bias=True)\n",
      "      (activation_0): ELU(alpha=1.0, inplace=True)\n",
      "      (linear_1): Linear(in_features=640, out_features=256, bias=True)\n",
      "      (activation_1): ELU(alpha=1.0, inplace=True)\n",
      "      (linear_2): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (src_embed): Embeddings(\n",
      "    (lut): Embedding(23, 128)\n",
      "  )\n",
      "  (tgt_embed): Embeddings(\n",
      "    (lut): Embedding(23, 128)\n",
      "  )\n",
      "  (generator): Generator(\n",
      "    (proj): Linear(in_features=128, out_features=22, bias=True)\n",
      "  )\n",
      "  (property_predictor): PropertyPredictor(\n",
      "    (prediction_layers): ListModule(\n",
      "      (0): Linear(in_features=32, out_features=2, bias=True)\n",
      "      (1): Linear(in_features=2, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "aae-128_peptide\n",
      "aae-128_peptide\n",
      "tensor(3.7572, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.7906, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(3.0256, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(1.4910, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1476, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.6986, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(2.0603, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2588, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.5793, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(2.3973, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3747, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4770, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(2.4877, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1495, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4045, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(2.3841, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1722, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4771, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(2.0332, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.0052, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4139, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(1.6207, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1987, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4310, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(1.1300, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1602, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4907, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.7496, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.0930, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.3981, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.4916, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1974, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.3721, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3684, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.3764, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3432, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2697, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.3508, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3802, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3240, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2902, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.4908, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3251, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2422, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.6345, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3236, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2407, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.8382, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3411, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2775, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.9616, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2762, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2127, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(1.0527, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2714, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2623, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(1.0295, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3074, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2109, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.9350, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3034, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1980, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.7989, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3152, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2630, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.6652, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3197, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1893, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.5568, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3493, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2179, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.4994, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3457, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2246, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.4329, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3540, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1818, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3841, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3380, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1610, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3285, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3234, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1520, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3094, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.3060, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1978, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2961, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2702, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2190, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2772, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2533, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1796, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2919, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2254, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1884, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2805, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1899, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2142, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3217, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1953, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1842, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3269, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2035, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1534, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3404, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2596, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2175, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3427, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2316, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2116, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3400, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2348, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1965, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.3139, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2094, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1743, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2810, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2339, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1927, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2302, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2241, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2078, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.2048, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2497, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2139, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1712, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2230, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.2209, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1449, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2303, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1816, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1559, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2789, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1913, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1474, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2379, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1869, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1375, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2238, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1866, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1390, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1928, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1805, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1294, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2125, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1465, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1369, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2169, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1822, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1442, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2444, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1436, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1218, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2333, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1810, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1162, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1910, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0959, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2124, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1474, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0835, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1754, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0914, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2566, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1497, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1084, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2494, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1523, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1118, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2420, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.0974, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1241, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2547, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1744, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1373, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2453, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1619, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1395, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2862, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1338, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1136, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2088, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1590, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0996, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2317, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1653, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0768, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1322, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0703, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2026, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1101, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0690, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1984, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1411, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0848, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1931, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1159, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1054, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1470, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1065, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1260, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2153, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1236, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1303, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1477, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1373, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1385, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1999, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.0984, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1204, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1838, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1585, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1108, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2208, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1209, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1188, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2146, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1346, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1051, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2345, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1493, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1061, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2159, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1160, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2413, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1434, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1309, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1274, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1739, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2321, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1100, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1567, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2191, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1349, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1520, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2276, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1335, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1442, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1991, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1604, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1412, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2228, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1367, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1493, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2386, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1304, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1402, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2064, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1302, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1531, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2352, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1185, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1265, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2078, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1365, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1188, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2650, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.0969, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.1035, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2161, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1505, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0899, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.0695, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0846, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2051, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1352, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0738, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.2332, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1235, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0873, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1478, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1107, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0850, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1891, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1370, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0790, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1288, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1009, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0740, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1895, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1122, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0887, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1328, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1104, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0900, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1780, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1059, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0772, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1889, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.1532, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.0760, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>) tensor(0.1342, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\scripts\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\scripts\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     vae.train(train_mols, test_mols, train_props, test_props,\n\u001b[0m\u001b[0;32m     86\u001b[0m               epochs=args.epochs, save_freq=args.save_freq)\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_mols, val_mols, train_props, val_props, epochs, save, save_freq, log, log_dir)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'aae'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#the aae loss is calculated in the forward function due to the 2 backward passes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m                         loss, bce, kld, prop_bce, disc_loss = self.model(src, tgt, true_prop,self.params['CHAR_WEIGHTS'], beta,\n\u001b[0m\u001b[0;32m    302\u001b[0m                                                                               self.optimizer, 'train', src_mask, tgt_mask)\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\aae_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt, true_prop, weights, beta, optimizer, train_test, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mprop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         tot_loss, bce, kld, prop_bce, disc_loss = loss.aae_loss(src, x, mu, logvar,\n\u001b[0m\u001b[0;32m    133\u001b[0m                                                                   \u001b[0mtrue_prop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                                                                   \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\loss.py\u001b[0m in \u001b[0;36maae_loss\u001b[1;34m(x, x_out, mu, logvar, true_prop, pred_prop, weights, self, latent_codes, opt, train_test, beta)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mBCE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#autoencoder loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'gpu'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HARDWARE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mvalid_discriminator_targets\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_codes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mvalid_discriminator_targets\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_codes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = 'aae'\n",
    "d_model = 128\n",
    "d_feedforward = 128\n",
    "d_latent = 32\n",
    "data_source = 'peptide'\n",
    "epochs = 1\n",
    "hardware = 'gpu'\n",
    "property_predictor = 'ON'\n",
    "type_property_predictor = 'deep_net'\n",
    "train_props_path = 'data\\\\function_train.txt'\n",
    "test_props_path = 'data\\\\function_test.txt'\n",
    "#DDP\n",
    "init_method = 'file:///D:/libtmp/file'\n",
    "dist_backend = 'gloo' #on windows NCCL not supported\n",
    "DDP = 'OFF' #ON or OFF\n",
    "#checkpoint = 'checkpointz\\\\amp_rnn\\\\sunistar_emb128_latent32_pp\\\\300_rnn-128_peptide.ckpt'\n",
    "%run scripts/train.py --model $model --d_model $d_model --d_feedforward $d_feedforward --d_latent $d_latent --data_source $data_source --epochs $epochs --hardware $hardware --init_method $init_method --dist_backend $dist_backend --DDP $DDP --property_predictor $property_predictor --type_property_predictor $type_property_predictor --train_props_path $train_props_path --test_props_path $test_props_path \n",
    "#--checkpoint $checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909711ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpointz//rnn_amp//emb64_latent64//log_rnn-64_peptide.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17500/2233528781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#loss ploting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'checkpointz//rnn_amp//emb64_latent64//log_rnn-64_peptide.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_loss_by_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, loss_type = 'kld_loss', data_type='test')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\analysis.py\u001b[0m in \u001b[0;36mplot_loss_by_type\u001b[1;34m(path, loss_types, colors)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'#008080'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#B86953'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#932191'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#90041F'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#0F4935'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\amp21\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpointz//rnn_amp//emb64_latent64//log_rnn-64_peptide.txt'"
     ]
    }
   ],
   "source": [
    "from transvae import analysis\n",
    "#loss ploting\n",
    "src = 'checkpointz//rnn_amp//emb64_latent64//log_rnn-64_peptide.txt'\n",
    "analysis.plot_loss_by_type(src)#, loss_type = 'kld_loss', data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b5dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn parser function called /n\n",
      "trans1x-128_peptide\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TransVAE' object has no attribute 'use_gpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\scripts\\attention.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mcalc_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\scripts\\attention.py\u001b[0m in \u001b[0;36mcalc_attention\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mmols_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mprops_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                     \u001b[0mmols_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmols_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mprops_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprops_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransVAE' object has no attribute 'use_gpu'"
     ]
    }
   ],
   "source": [
    "#extracting attention weights\n",
    "\n",
    "%run scripts/attention.py --model transvae --model_ckpt checkpointz\\\\amp_trans\\\\sunistarv3_emb128_latent128_pp\\\\300_trans1x-128_peptide.ckpt --mols data\\\\peptide_test.txt --save_path \"attn_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f16cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
