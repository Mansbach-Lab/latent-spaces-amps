{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ab15f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory:  C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\n",
      "working on:  checkpointz\\to_slurm\\aae_latent128\\300_aae-128_peptide.ckpt \n",
      "\n",
      "log_aae-128_peptide.txt checkpointz\\to_slurm\\aae_latent128\\log_aae-128_peptide.txt\n",
      "aae-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\aae_latent32\\300_aae-128_peptide.ckpt \n",
      "\n",
      "log_aae-128_peptide.txt checkpointz\\to_slurm\\aae_latent32\\log_aae-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aae-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\aae_latent64\\300_aae-128_peptide.ckpt \n",
      "\n",
      "log_aae-128_peptide.txt checkpointz\\to_slurm\\aae_latent64\\log_aae-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aae-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\rnnattn_latent128\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "log_rnnattn-128_peptide.txt checkpointz\\to_slurm\\rnnattn_latent128\\log_rnnattn-128_peptide.txt\n",
      "rnnattn-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\rnnattn_latent32\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "log_rnnattn-128_peptide.txt checkpointz\\to_slurm\\rnnattn_latent32\\log_rnnattn-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnnattn-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\rnnattn_latent64\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "log_rnnattn-128_peptide.txt checkpointz\\to_slurm\\rnnattn_latent64\\log_rnnattn-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnnattn-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\rnn_latent128\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "log_rnn-128_peptide.txt checkpointz\\to_slurm\\rnn_latent128\\log_rnn-128_peptide.txt\n",
      "rnn-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\rnn_latent32\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "log_rnn-128_peptide.txt checkpointz\\to_slurm\\rnn_latent32\\log_rnn-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\rnn_latent64\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "log_rnn-128_peptide.txt checkpointz\\to_slurm\\rnn_latent64\\log_rnn-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\trans_latent128\\300_trans1x-128_peptide.ckpt \n",
      "\n",
      "log_trans1x-128_peptide.txt checkpointz\\to_slurm\\trans_latent128\\log_trans1x-128_peptide.txt\n",
      "trans1x-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\trans_latent32\\300_trans1x-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_trans1x-128_peptide.txt checkpointz\\to_slurm\\trans_latent32\\log_trans1x-128_peptide.txt\n",
      "trans1x-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\trans_latent64\\300_trans1x-128_peptide.ckpt \n",
      "\n",
      "log_trans1x-128_peptide.txt checkpointz\\to_slurm\\trans_latent64\\log_trans1x-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans1x-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\wae_latent128\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "log_wae-128_peptide.txt checkpointz\\to_slurm\\wae_latent128\\log_wae-128_peptide.txt\n",
      "wae-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\wae_latent32\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAE class build_model called /n\n",
      "log_wae-128_peptide.txt checkpointz\\to_slurm\\wae_latent32\\log_wae-128_peptide.txt\n",
      "wae-128_peptide\n",
      "working on:  checkpointz\\to_slurm\\wae_latent64\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "log_wae-128_peptide.txt checkpointz\\to_slurm\\wae_latent64\\log_wae-128_peptide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wae-128_peptide\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from transvae import trans_models\n",
    "from transvae.transformer_models import TransVAE\n",
    "from transvae.rnn_models import RNN, RNNAttn\n",
    "from transvae.wae_models import WAE\n",
    "from transvae.aae_models import AAE\n",
    "from transvae.tvae_util import *\n",
    "from transvae import analysis\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import trustworthiness\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import coranking #coranking.readthedocs.io\n",
    "from coranking.metrics import trustworthiness, continuity, LCMC\n",
    "from transvae.snc import SNC #github.com/hj-n/steadiness-cohesiveness\n",
    "\n",
    "def loss_plots(loss_src):\n",
    "    tot_loss = analysis.plot_loss_by_type(src,loss_types=['tot_loss'])\n",
    "    plt.savefig(save_dir+'tot_loss.png')\n",
    "    recon_loss = analysis.plot_loss_by_type(src,loss_types=['recon_loss'])\n",
    "    plt.savefig(save_dir+'recon_loss.png')\n",
    "    kld_loss = analysis.plot_loss_by_type(src,loss_types=['kld_loss'])\n",
    "    plt.savefig(save_dir+'kld_loss.png')\n",
    "    prob_bce_loss = analysis.plot_loss_by_type(src,loss_types=['prop_bce_loss'])\n",
    "    plt.savefig(save_dir+'prob_bce_loss.png')\n",
    "    if 'aae' in src:\n",
    "        disc_loss = analysis.plot_loss_by_type(src,loss_types=['disc_loss'])\n",
    "        plt.savefig(save_dir+'disc_loss.png')\n",
    "    if 'wae' in src:\n",
    "        mmd_loss = analysis.plot_loss_by_type(src,loss_types=['mmd_loss'])\n",
    "        plt.savefig(save_dir+'mmd_loss.png')\n",
    "    plt.close('all')\n",
    "    \n",
    "def load_reconstructions(data,data_1D,latent_size, load_src, true_props=None,subset=None):\n",
    "    \n",
    "    recon_src = load_src+model.name+\"_\"+re.split('(\\d{2,3})',latent_size[0])[0]+\"_\"+re.split('(\\d{2,3})',latent_size[0])[1]+\"//saved_info.csv\"\n",
    "    recon_df = pd.read_csv(recon_src)\n",
    "    reconstructed_seq = recon_df['reconstructions'].to_list()[:num_sequences]\n",
    "    props = torch.Tensor(recon_df['predicted properties'][:num_sequences])\n",
    "    true_props_data = pd.read_csv(true_props).to_numpy()\n",
    "    true_props = true_props_data[0:num_sequences,0]\n",
    "    \n",
    "    if subset:\n",
    "        testing = pd.read_csv(subset).to_numpy()\n",
    "        test_idx_list = [np.where(data==testing[idx][0]) for idx in range(len(testing))]\n",
    "\n",
    "\n",
    "        batch_recon_len = len(reconstructed_seq)\n",
    "        reconstructed_seq = [reconstructed_seq[test_idx_list[i][0][0]] for i in range(len(test_idx_list)) if test_idx_list[i][0][0]<batch_recon_len]\n",
    "        data_1D= [data_1D[test_idx_list[i][0][0]] for i in range(len(test_idx_list)) if test_idx_list[i][0][0]<batch_recon_len]\n",
    "        props = [props[test_idx_list[i][0][0]] for i in range(len(test_idx_list)) if test_idx_list[i][0][0]<batch_recon_len]\n",
    "        props=torch.Tensor(props)\n",
    "        data = testing[:][0]\n",
    "        true_props_data = pd.read_csv(true_props).to_numpy()\n",
    "        true_props = true_props_data[0:num_sequences,0]\n",
    "        true_props= [true_props[test_idx_list[i][0][0]] for i in range(len(test_idx_list)) if test_idx_list[i][0][0]<batch_recon_len]\n",
    "\n",
    "    return data, data_1D, true_props, props, reconstructed_seq\n",
    "\n",
    "########################################################################################\n",
    "gpu = True\n",
    "\n",
    "num_sequences = 500#_000\n",
    "batch_size = 200 #setting for reconstruction\n",
    "example_data = 'data\\\\peptides\\\\datasets\\\\uniprot_v2\\\\peptide_test.txt'\n",
    "save_dir_loc = 'model_analyses\\\\test\\\\' #folder in which to save outpts\n",
    "save_dir_name = 'test' #appended to identify data: train|test|other|etc...\n",
    "\n",
    "reconstruct=True #True:reconstruct data here; False:load reconstructions from file\n",
    "recon_src = \"checkpointz//analyses_ckpts//\" #directory in which all reconstructions are stored\n",
    "true_prop_src = 'data\\\\peptides\\\\datasets\\\\uniprot_v2\\\\function_test.txt' #if property predictor load the true labels\n",
    "subset_src = \"\" #(optional) this file should have the true sequences for a subset of the \"example data\" above\n",
    "\n",
    "ckpt_list = glob.glob(\"\"+\"checkpointz\\\\to_slurm//**//*.ckpt\", recursive = True) #grab all checkpoint\n",
    "print('current working directory: ',os.getcwd())\n",
    "\n",
    "\n",
    "for i in range(len(ckpt_list)):\n",
    "    #search the current directory for the model name and load that model\n",
    "    model_dic = {'trans':'TransVAE','aae':'AAE','rnnattn':'RNNAttn','rnn':'RNN','wae':'WAE'}\n",
    "    model_src = ckpt_list[i]\n",
    "    print('working on: ',model_src,'\\n')\n",
    "    model_name = list(filter(None,[key for key in model_dic.keys() if key in model_src.split('\\\\')[-1]]))\n",
    "    model = locals()[model_dic[model_name[0]]](load_fn=model_src) #use locals to call model specific constructor\n",
    "    \n",
    "    #create save directory for the current model according to latent space size\n",
    "    latent_size = re.findall('(latent[\\d]{2,3})', model_src)\n",
    "    save_dir= save_dir_loc+model.name+\"_\"+latent_size[0]+\"_\"+save_dir_name\n",
    "    if not os.path.exists(save_dir):os.mkdir(save_dir) \n",
    "    save_dir= save_dir+\"//\" \n",
    "    save_df = pd.DataFrame() #this will hold the number variables and save to CSV\n",
    "    \n",
    "    #load the true labels\n",
    "    data = pd.read_csv(example_data).to_numpy() \n",
    "    data_1D = data[:num_sequences,0] #gets rid of extra dimension\n",
    "    true_props_data = pd.read_csv(true_prop_src).to_numpy()\n",
    "    true_props = true_props_data[0:num_sequences,0]\n",
    "\n",
    "    \n",
    "    #get the log.txt file from the ckpt and model name then plot loss curves\n",
    "    loss_src = '_'.join( (\"log\",model_src.split('\\\\')[-1].split('_')[1],model_src.split('\\\\')[-1].split('_')[2][:-4]+\"txt\") )\n",
    "    src= '\\\\'.join([str(i) for i in model_src.split('\\\\')[:-1]])+\"\\\\\"+loss_src\n",
    "    print(loss_src, src)\n",
    "    loss_plots(src)\n",
    "    \n",
    "#     #set the batch size and reconstruct the data\n",
    "#     model.params['BATCH_SIZE'] = batch_size\n",
    "#     if reconstruct:\n",
    "#         reconstructed_seq, props = model.reconstruct(data[:num_sequences], log=False, return_mems=False)\n",
    "#     else:\n",
    "#         data, data_1D, true_props, props, reconstructed_seq = load_reconstructions(data, data_1D,latent_size,\n",
    "#                                                                                    load_src=recon_src,\n",
    "#                                                                                    true_props=true_prop_src)\n",
    "#     if gpu:torch.cuda.empty_cache() #free allocated CUDA memory\n",
    "    \n",
    "#     #save the metrics to the dataframe\n",
    "#     save_df['reconstructions'] = reconstructed_seq #placing the saves on a line separate from the ops allows for editing\n",
    "#     save_df['predicted properties'] = [prop.item() for prop in props[:len(reconstructed_seq)]]\n",
    "#     prop_acc, prop_conf, MCC=calc_property_accuracies(props[:len(reconstructed_seq)],true_props[:len(reconstructed_seq)], MCC=True)\n",
    "#     save_df['property prediction accuracy'] = prop_acc\n",
    "#     save_df['property prediction confidence'] = prop_conf\n",
    "#     save_df['MCC'] = MCC\n",
    "    \n",
    "\n",
    "# #   First we tokenize the input and reconstructed smiles\n",
    "#     input_sequences = []\n",
    "#     for seq in data_1D:\n",
    "#         input_sequences.append(peptide_tokenizer(seq))\n",
    "#     output_sequences = []\n",
    "#     for seq in reconstructed_seq:\n",
    "#         output_sequences.append(peptide_tokenizer(seq))\n",
    "    \n",
    "#     seq_accs, tok_accs, pos_accs, seq_conf, tok_conf, pos_conf = calc_reconstruction_accuracies(input_sequences, output_sequences)\n",
    "#     save_df['sequence accuracy'] = seq_accs\n",
    "#     save_df['sequence confidence'] = seq_conf\n",
    "#     save_df['token accuracy'] = tok_accs\n",
    "#     save_df['token confidence'] = tok_conf\n",
    "#     save_df = pd.concat([pd.DataFrame({'position_accs':pos_accs,'position_confidence':pos_conf }), save_df], axis=1)\n",
    "    \n",
    "    ##moving into memory and entropy\n",
    "    if model.model_type =='aae':\n",
    "        mus, _, _ = model.calc_mems(data[:50_000], log=False, save=False) #50_000\n",
    "    elif model.model_type == 'wae':\n",
    "        mus, _, _ = model.calc_mems(data[:50_000], log=False, save=False) \n",
    "    else:\n",
    "        mems, mus, logvars = model.calc_mems(data[:50_000], log=False, save=False) #subset size 1200*35=42000 would be ok\n",
    "\n",
    "#     ##calculate the entropies\n",
    "#     vae_entropy_mus = calc_entropy(mus)\n",
    "#     save_df = pd.concat([save_df,pd.DataFrame({'mu_entropies':vae_entropy_mus})], axis=1)\n",
    "#     if model.model_type != 'wae' and model.model_type!= 'aae': #these don't have a variational type bottleneck\n",
    "#         vae_entropy_mems  = calc_entropy(mems)\n",
    "#         save_df = pd.concat([save_df,pd.DataFrame({'mem_entropies':vae_entropy_mems})], axis=1)\n",
    "#         vae_entropy_logvars = calc_entropy(logvars)\n",
    "#         save_df = pd.concat([save_df,pd.DataFrame({'logvar_entropies':vae_entropy_logvars})], axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    #create random index and re-index ordered memory list creating n random sub-lists (ideally resulting in IID random lists)\n",
    "    random_idx = np.random.permutation(np.arange(stop=mus.shape[0]))\n",
    "    mus = mus[random_idx]\n",
    "    shuf_data = data[random_idx]\n",
    "\n",
    "    subsample_start=0\n",
    "    subsample_length=mus.shape[0] #this may change depending on batch size\n",
    "\n",
    "    #(for length based coloring): record all peptide lengths iterating through input\n",
    "    pep_lengths = []\n",
    "    for idx, pep in enumerate(shuf_data[subsample_start:(subsample_start+subsample_length)]):\n",
    "        pep_lengths.append( len(pep[0]) )   \n",
    "    #(for function based coloring): pull function from csv with peptide functions\n",
    "    s_to_f =pd.read_csv(true_prop_src)    \n",
    "    function = s_to_f['peptides'][subsample_start:(subsample_start+subsample_length)]\n",
    "    function = function[random_idx] #account for random permutation\n",
    "\n",
    "    pca = PCA(n_components=5)\n",
    "    pca_batch =pca.fit_transform(X=mus[:])\n",
    "\n",
    "    #plot format dictionnaries\n",
    "    titles={'text':'{}'.format(model.model_type.replace(\"_\",\" \").upper()),\n",
    "                          'x':0.5,'xanchor':'center','yanchor':'top','font_size':40}\n",
    "    general_fonts={'family':\"Helvetica\",'size':30,'color':\"Black\"}\n",
    "    colorbar_fmt={'title_font_size':30,'thickness':15,'ticks':'','title_text':'Lengths',\n",
    "                               'ticklabelposition':\"outside bottom\"}\n",
    "    \n",
    "    fig = px.scatter(pd.DataFrame({\"PC1\":pca_batch[:,0],\"PC2\":pca_batch[:,1], \"lengths\":pep_lengths}),\n",
    "                symbol_sequence=['hexagon2'],x='PC1', y='PC2', color=\"lengths\",\n",
    "                color_continuous_scale='Jet',template='simple_white', opacity=0.9)\n",
    "    fig.update_traces(marker=dict(size=9))\n",
    "    fig.update_layout(title=titles,xaxis_title=\"PC1\", yaxis_title=\"PC2\",font=general_fonts)\n",
    "    fig.update_coloraxes(colorbar=colorbar_fmt)\n",
    "    fig.write_image(save_dir+'pca_length.png', width=900, height=600)\n",
    "\n",
    "    fig = px.scatter(pd.DataFrame({\"PC1\":pca_batch[:,0],\"PC2\":pca_batch[:,1], \n",
    "                                    \"Function\":list(map(lambda itm: \"AMP\" if itm==1 else \"NON-AMP\",function))}),\n",
    "                                    x='PC1', y='PC2', color=\"Function\",symbol_sequence=['x-thin-open','circle'],\n",
    "                                    template='simple_white',symbol='Function', opacity=0.8) \n",
    "    fig.update_traces(marker=dict(size=9))\n",
    "    fig.update_layout(title=titles,xaxis_title=\"PC1\",yaxis_title=\"PC2\",font=general_fonts)\n",
    "    fig.write_image(save_dir+'pca_function.png', width=900, height=600)\n",
    "    \n",
    "    # Plot the explained variances\n",
    "    plt.bar(range(pca.n_components_), pca.explained_variance_ratio_*100, color='black')\n",
    "    plt.xlabel('PCA features')\n",
    "    plt.ylabel('variance %')\n",
    "    plt.xticks(range(pca.n_components_))\n",
    "    plt.savefig(save_dir+'variance_explained.png')\n",
    "\n",
    "    fig = px.scatter_matrix(pd.DataFrame({\"PC1\":pca_batch[:,0],\"PC2\":pca_batch[:,1],\"PC3\":pca_batch[:,2],\n",
    "                                          \"PC4\":pca_batch[:,3],\"PC5\":pca_batch[:,4],\"lengths\":pep_lengths}),\n",
    "                                    dimensions=[\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\"],\n",
    "                                    symbol_sequence=['hexagon2'],template='simple_white',\n",
    "                                    color=\"lengths\",color_continuous_scale='Jet', opacity=0.9)\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    fig.update_layout(title=titles,font=general_fonts)\n",
    "    fig.write_image(save_dir+'pca_matrix_length.png', width=5_000, height=2500) \n",
    "    \n",
    "    fig = px.scatter_matrix(pd.DataFrame({\"PC1\":pca_batch[:,0],\"PC2\":pca_batch[:,1],\"PC3\":pca_batch[:,2],\n",
    "                                          \"PC4\":pca_batch[:,3],\"PC5\":pca_batch[:,4],\n",
    "                                   \"Function\":list(map(lambda itm: \"AMP\" if itm==1 else \"NON-AMP\",function))}),\n",
    "                                    dimensions=[\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\"],template='simple_white',\n",
    "                                    color=\"Function\",symbol_sequence=['x-thin','circle'],\n",
    "                                    symbol='Function', opacity=0.8) \n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    fig.update_layout(title=titles,font=general_fonts)\n",
    "    fig.write_image(save_dir+'pca_matrix_function.png', width=5_000, height=2500) \n",
    "    pearson = {} #dict to store the pearson coefficient between PCA vs AMP function or physicochem.props.\n",
    "    pearson.update({'amp'+'_spearmanr':[(spearmanr(pca_batch[:,pc],function).correlation,\n",
    "                                         spearmanr(pca_batch[:,pc],function).pvalue) for pc in range(5)]})\n",
    "    if 'train' in save_dir_name:\n",
    "        phys_props = pd.read_csv('data\\\\train_physicochem_props.csv')\n",
    "    else:\n",
    "        phys_props = pd.read_csv('data\\\\test_physicochem_props.csv')\n",
    "\n",
    "    \n",
    "    for col in phys_props.columns:\n",
    "        functions = phys_props[col][:len(mus)].values\n",
    "        functions = functions[random_idx] #keeping track of data scrambling...\n",
    "        pearson.update({str(col)+'_pearsonr':[pearsonr(pca_batch[:,pc],functions) for pc in range(5)]})\n",
    "        fig = px.scatter_matrix(pd.DataFrame({\"PC1\":pca_batch[:,0],\"PC2\":pca_batch[:,1],\"PC3\":pca_batch[:,2],\n",
    "                                                  \"PC4\":pca_batch[:,3],\"PC5\":pca_batch[:,4],\n",
    "                                           \"Function\":functions}),\n",
    "                                            dimensions=[\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\"],template='simple_white',\n",
    "                                            color=\"Function\",opacity=0.9) \n",
    "        colorbar_fmt={'title_font_size':30,'thickness':15,'ticks':'','title_text':str(col),\n",
    "                               'ticklabelposition':\"outside bottom\"}\n",
    "        fig.update_traces(diagonal_visible=False)\n",
    "        fig.update_layout(title=titles,font=general_fonts)\n",
    "        fig.update_coloraxes(colorbar=colorbar_fmt, \n",
    "                             cmax=np.mean(functions)+np.std(functions),\n",
    "                             cmin=np.mean(functions)-np.std(functions),\n",
    "                             cmid=np.mean(functions))\n",
    "        fig.write_image(save_dir+col+'_PCA_matrix'+'.png', width=5_000, height=2500) \n",
    "    df_pearson = pd.DataFrame.from_dict(pearson)\n",
    "    df_pearson.to_csv(save_dir+'pearsonr.csv', index=False)\n",
    "\n",
    "#     #first calculate silhouette score on all latent space dims\n",
    "#     n=15\n",
    "#     latent_mem_func_subsamples = []\n",
    "#     for s in range(n):\n",
    "#         s_len = len(mus)//n #sample lengths\n",
    "#         mem_func_sil = metrics.silhouette_score(mus[s_len*s:s_len*(s+1)], function[s_len*s:s_len*(s+1)], metric='euclidean')\n",
    "#         latent_mem_func_subsamples.append(mem_func_sil)\n",
    "#     save_df = pd.concat([save_df,pd.DataFrame({'latent_mem_func_silhouette':latent_mem_func_subsamples})], axis=1)\n",
    "#     #then go over pairs of PC's from PCA and find max SS PC's\n",
    "#     pc_pairs = [[0,1],[0,2],[0,3],[0,4],[1,2],[1,3],[1,4],[2,3],[2,4],[3,4]]\n",
    "#     for pc_pair in pc_pairs:\n",
    "#         print(\"working on PC[{},{}]\".format(pc_pair[0],pc_pair[1]))\n",
    "#         pca_func_subsamples = []\n",
    "#         for s in range(n):\n",
    "#             s_len = len(mus)//n #sample lengths\n",
    "#             XY = [i for i in zip(pca_batch[s_len*s:s_len*(s+1),pc_pair[0]], pca_batch[s_len*s:s_len*(s+1),pc_pair[1]])]\n",
    "#             pca_func_sil = metrics.silhouette_score(XY, function[s_len*s:s_len*(s+1)], metric='euclidean')\n",
    "#             pca_func_subsamples.append(pca_func_sil)\n",
    "#         save_df = pd.concat([save_df,pd.DataFrame({'pca_func_silhouette[{},{}]'.format(pc_pair[0],pc_pair[1]):pca_func_subsamples})], axis=1)\n",
    "#     print( np.argmax(save_df.drop(columns=save_df.columns[0]).mean(axis=0)) )\n",
    "#     save_df.to_csv(save_dir+\"saved_info.csv\", index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "#New section dealing with sequence generation metrics and bootstrapping from the latent space\n",
    "    #first randomly sample points within the latents space\n",
    "#     rnd_seq_count =1_000 \n",
    "#     rnd_latent_list=[] #generate N latent space vectors\n",
    "#     mem_min = np.min(mus)\n",
    "#     mem_max = np.max(mus)\n",
    "#     for seq in range(rnd_seq_count):\n",
    "#         rnd_latent_list.append( np.array([random.uniform(mem_min,mem_max) for i in range(model.params['d_latent'])]).astype(np.float32) )\n",
    "    \n",
    "#     model.params['BATCH_SIZE'] = 25\n",
    "#     rnd_token_list=np.empty((rnd_seq_count,model.tgt_len)) #store N decoded latent vectors now in token(0-20) form max length 125\n",
    "    \n",
    "#     #decode these points into predicted amino acid tokens (integers)\n",
    "#     for batch in range(0,rnd_seq_count,model.params['BATCH_SIZE']):\n",
    "#         rnd_token_list[batch:batch+model.params['BATCH_SIZE']] =  model.greedy_decode(torch.tensor(rnd_latent_list[batch:batch+model.params['BATCH_SIZE']]).cuda()).cpu()\n",
    "    \n",
    "#     #turn the tokens into characters\n",
    "#     decoded_rnd_seqs = decode_mols(torch.tensor(rnd_token_list), model.params['ORG_DICT'])\n",
    "#     decoded_rnd_seqs[:]=[x for x in decoded_rnd_seqs if x] #removes the empty lists\n",
    "    \n",
    "#     df_gen_scores = {} #dictionnary to store results\n",
    "#     #UNIQUENESS\n",
    "#     percent_unique, unique_conf = uniqueness(decoded_rnd_seqs)\n",
    "#     df_gen_scores.update({'percent_unique': percent_unique})\n",
    "#     df_gen_scores.update({'unique_confidence':unique_conf})\n",
    "    \n",
    "#     #NOVELTY\n",
    "#     #sample N test/train set sequences randomly and compare to those created\n",
    "#     percent_novel, novel_conf = novelty(data, np.expand_dims(np.array(decoded_rnd_seqs),1))\n",
    "#     df_gen_scores.update({'percent_novel':percent_novel})\n",
    "#     df_gen_scores.update({'novel_confidence':novel_conf})\n",
    "    \n",
    "#     #AMP SAMPLING\n",
    "#     peptides_to_probe=10\n",
    "#     sample_count=30\n",
    "#     best_pc = np.argmax([np.abs(pearsonr(pca_batch[:,pc],function)[0]) for pc in range(5)]) #find the best PCvsAMP correlation\n",
    "#     pca_min = np.min(pca_batch[:,best_pc])\n",
    "#     pca_max = np.max(pca_batch[:,best_pc])\n",
    "#     pca_scan = np.zeros((peptides_to_probe,5)) #create a reduced vector to be sent backwards to high-D\n",
    "#     pca_scan[:,best_pc]=np.linspace(start=pca_min, stop=pca_max, num=peptides_to_probe) #scan 1 dim evenly with best PC\n",
    "#     amp_sample_latents = pca.inverse_transform(pca_scan) #inverse to high-Dims for decoding\n",
    "#     all_gen_seqs = [] #stored in a text file for AMP prediction later\n",
    "#     for idx,amp in enumerate(amp_sample_latents):\n",
    "#         print(\"working on amp sample number: \",idx)\n",
    "#         mus=np.expand_dims(amp.astype(np.float32),0)\n",
    "#         nearby_samples = np.random.normal(loc=0,scale=1,size=(sample_count,1,model.params['d_latent'])).astype(np.float32)*0.3 + mus\n",
    "#         model.params['BATCH_SIZE'] = 25\n",
    "#         rnd_token_list=np.empty((sample_count,model.tgt_len)) #store N decoded latent vectors now in token(0-20) form max length 125\n",
    "#         for batch in range(0,sample_count,model.params['BATCH_SIZE']):\n",
    "#             rnd_token_list[batch:batch+model.params['BATCH_SIZE']] =  model.greedy_decode(torch.tensor(nearby_samples[batch:batch+model.params['BATCH_SIZE']]).squeeze().cuda()).cpu()\n",
    "#         decoded_rnd_seqs = decode_mols(torch.tensor(rnd_token_list), model.params['ORG_DICT'])\n",
    "        \n",
    "               \n",
    "#         for seq in decoded_rnd_seqs:\n",
    "#             all_gen_seqs.append(seq)\n",
    "#         decoded_rnd_seqs = [seq for seq in decoded_rnd_seqs if len(seq)>0] #drop the empy sequences\n",
    "        \n",
    "#         #SEQ SIMILARITY\n",
    "#         similarity_score = sequence_similarity(decoded_rnd_seqs)  \n",
    "#         df_gen_scores.update({'average_sequence_similarity_'+str(idx): np.average(similarity_score)})\n",
    "#         df_gen_scores.update({'std_on_similarity_score_'+str(idx): np.std(similarity_score)})\n",
    "        \n",
    "#         #AMP UNIQUENESS\n",
    "#         amp_percent_unique, amp_unique_conf = uniqueness(decoded_rnd_seqs)\n",
    "#         df_gen_scores.update({'amp_uniqueness_'+str(idx): amp_percent_unique})\n",
    "#         df_gen_scores.update({'amp_uniqueness_std_'+str(idx): amp_unique_conf})\n",
    "        \n",
    "#         #Jaccard Similarity Score\n",
    "#         jac_scores_2 = jaccard_similarity_score(decoded_rnd_seqs,2)\n",
    "#         jac_scores_3 = jaccard_similarity_score(decoded_rnd_seqs,3)\n",
    "#         df_gen_scores.update({'amp_jac_score_2_'+str(idx): np.average(jac_scores_2)})\n",
    "#         df_gen_scores.update({'amp_jac_score_std_2_'+str(idx): np.std(jac_scores_2)})\n",
    "#         df_gen_scores.update({'amp_jac_score_3_'+str(idx): np.average(jac_scores_3)})\n",
    "#         df_gen_scores.update({'amp_jac_score_std_3_'+str(idx): np.std(jac_scores_3)})\n",
    "    \n",
    "#     #Store Output\n",
    "#     with open(save_dir+'all_gen_seqs.txt','w') as f:\n",
    "#         for seq in all_gen_seqs:\n",
    "#             f.write(str(seq)+\"\\n\")\n",
    "#     df = pd.DataFrame.from_dict([df_gen_scores])\n",
    "#     pd.DataFrame.from_dict([df_gen_scores]).to_csv(save_dir+\"generation_metrics.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307e206",
   "metadata": {},
   "source": [
    "<H4>Since Compute Canada does not do the dimensionality reduction metrics we need to do them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fc2219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory:  C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\n",
      "working on:  checkpointz\\to_slurm\\aae_latent128\\300_aae-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\aae-128_peptide_latent128_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\aae_latent128\\300_aae-128_peptide.ckpt\n",
      "aae-128_peptide\n",
      "0 0.8302777117363083 0.8802514029830146 0.12416861109784344\n",
      "0.8021271832930836 0.7131013082619109\n",
      "1 0.8330010491048477 0.8849852409881493 0.11999433373022127\n",
      "0.823952404375804 0.6731206728892155\n",
      "2 0.8384108356678447 0.8855374320262078 0.12188120052992525\n",
      "0.8182679651467646 0.6874399748799729\n",
      "3 0.8382689469103471 0.8853910884692464 0.12145384925631005\n",
      "0.8026112373420478 0.7055760061581462\n",
      "4 0.833973408953818 0.885358476768385 0.11840152285502772\n",
      "0.8130479647235245 0.6771931272866757\n",
      "5 0.8369093254879482 0.8854397636166487 0.1218365053857598\n",
      "0.8202771383862371 0.6806602047004187\n",
      "6 0.8290242290348175 0.8792937366674517 0.11962778946796075\n",
      "0.815886347895445 0.6866688563630503\n",
      "7 0.8303597969262029 0.8805099251009475 0.1148821353074974\n",
      "0.8158406139863527 0.6702314723702136\n",
      "8 0.8263649534805203 0.8789796894783849 0.11671334590083628\n",
      "0.8083154425796197 0.6896037443871195\n",
      "9 0.8352361148647801 0.8854524846470355 0.11914257140958266\n",
      "0.8226240516654224 0.6820083826530725\n",
      "10 0.8371664982997681 0.8869614036993393 0.11826878731394751\n",
      "0.8202458801765452 0.6939623577501577\n",
      "11 0.8289814454421256 0.8771143797515358 0.11357507456817915\n",
      "0.825194743356766 0.6563788197596842\n",
      "12 0.8373254277954194 0.8875247882212374 0.12302418349877346\n",
      "0.8309667416470508 0.6631836023268638\n",
      "13 0.8382974930318894 0.8870586933077788 0.11924048327467306\n",
      "0.8185384371263791 0.6992814834443624\n",
      "14 0.8323287970955205 0.8812808236991165 0.11781851980113035\n",
      "0.8175354529301866 0.6755822269678495\n",
      "working on:  checkpointz\\to_slurm\\aae_latent32\\300_aae-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\aae-128_peptide_latent32_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\aae_latent32\\300_aae-128_peptide.ckpt\n",
      "aae-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7600417815039993 0.8549679240355698 0.09881150309882607\n",
      "0.7304666898304422 0.6689619082472802\n",
      "1 0.7434343648815366 0.8459461372081621 0.09157987108312216\n",
      "0.7230706669975837 0.6579112932757039\n",
      "2 0.7601914747145255 0.8545445051397355 0.09692768962840484\n",
      "0.7378277731751821 0.666614336808776\n",
      "3 0.7567649615778516 0.854208817021764 0.09682214458963377\n",
      "0.7443521531288059 0.6571462301357864\n",
      "4 0.7613898144176768 0.8581184972761141 0.10445522843677703\n",
      "0.7322508173233998 0.6523470435142786\n",
      "5 0.7548625584130721 0.8510460336132378 0.09662431785452337\n",
      "0.7183852097881469 0.6753079807155002\n",
      "6 0.7432269004657063 0.8466054990042239 0.09273020277063593\n",
      "0.7087440549940396 0.6597335740530212\n",
      "7 0.7519584242294244 0.8525189814005324 0.09905583133879528\n",
      "0.7181692997314675 0.6750105927211472\n",
      "8 0.752505009806922 0.8541801797626228 0.09733898851517259\n",
      "0.7311067895705317 0.6759535467264579\n",
      "9 0.7458245907272166 0.8453162220415275 0.09246157748718734\n",
      "0.7093765983524298 0.6717671727010783\n",
      "10 0.755710850475864 0.851886518261578 0.10157395366773696\n",
      "0.738837092811039 0.6565087327989221\n",
      "11 0.7531969674857564 0.8512010628020918 0.09845669719987657\n",
      "0.7238296227775395 0.6783663703759284\n",
      "12 0.7501495973431166 0.8488669460319269 0.09355880199478335\n",
      "0.7171834373905923 0.664104878061928\n",
      "13 0.7549185847610439 0.8525018325129186 0.10332041366544135\n",
      "0.7208344433857288 0.664479636287083\n",
      "14 0.7501596673433584 0.8480377191174591 0.09218520231522807\n",
      "0.7042604253140934 0.675282068085717\n",
      "working on:  checkpointz\\to_slurm\\aae_latent64\\300_aae-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\aae-128_peptide_latent64_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\aae_latent64\\300_aae-128_peptide.ckpt\n",
      "aae-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7834516967932477 0.8580754526560782 0.09678576010164755\n",
      "0.7604636848812987 0.6893751414419041\n",
      "1 0.7743132226807024 0.8524519343878366 0.10130143373296263\n",
      "0.7472723682494425 0.6834994775434828\n",
      "2 0.7841020263091508 0.8577118135509808 0.10512396340324277\n",
      "0.7706715304139302 0.6698788893209997\n",
      "3 0.7908943461440002 0.8624430726843788 0.10725714387664365\n",
      "0.7649903603736826 0.6782179627092231\n",
      "4 0.7880292285189355 0.8600867235522627 0.10560710067664024\n",
      "0.7625973400021329 0.6928882886782847\n",
      "5 0.7757735855748614 0.8503557228141815 0.10004842355180546\n",
      "0.7631725865176507 0.6806207875988295\n",
      "6 0.7875464541918201 0.8580190664649961 0.10072182922849626\n",
      "0.782351839716679 0.6496939456383919\n",
      "7 0.7900962391566115 0.8636384393387027 0.10649006387757885\n",
      "0.7812796440377164 0.6693866959580221\n",
      "8 0.7855739418293964 0.8596937380729212 0.10440545236476952\n",
      "0.775035290773975 0.6609270882693918\n",
      "9 0.7856604792691282 0.858916517038271 0.09939802573350126\n",
      "0.7694781590974652 0.6688220144482875\n",
      "10 0.7768796901009811 0.8501753692323596 0.09311336964995931\n",
      "0.7646240802788508 0.6644316415388927\n",
      "11 0.784172184604427 0.8569697116108358 0.10059271694215209\n",
      "0.7762114991323549 0.6580086442206421\n",
      "12 0.7845645797669009 0.8583094804868365 0.10108496201448293\n",
      "0.7717184034839566 0.6360306589603891\n",
      "13 0.7782176174491008 0.8545817154588914 0.09397071786204746\n",
      "0.7640737953857436 0.676057814576585\n",
      "14 0.7852360762271317 0.8592591366695028 0.10207723788052706\n",
      "0.7776969167159743 0.6709666005647019\n",
      "working on:  checkpointz\\to_slurm\\rnnattn_latent128\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\rnnattn-128_peptide_latent128_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\rnnattn_latent128\\300_rnnattn-128_peptide.ckpt\n",
      "rnnattn-128_peptide\n",
      "0 0.7193212345316433 0.8210011714561201 0.08059519302837329\n",
      "0.71565483158045 0.6435390668828949\n",
      "1 0.726729103006963 0.8223547194160805 0.08512959520028758\n",
      "0.7234410262879643 0.6429274768786455\n",
      "2 0.7149066914094301 0.8196539571563225 0.08204084463498504\n",
      "0.7342245851328427 0.6281296410364532\n",
      "3 0.7159614269707218 0.8160597555416823 0.07742137336167582\n",
      "0.7076391489062646 0.6294227595194921\n",
      "4 0.7192290347006828 0.8205719406770379 0.08667437086143026\n",
      "0.7433513139051313 0.6200066265688722\n",
      "5 0.7142083329645127 0.8164789860968719 0.082587487872268\n",
      "0.7247913916288917 0.619406401615554\n",
      "6 0.7176960354653644 0.816454094581435 0.08117097219282109\n",
      "0.7418100131510391 0.603511715592131\n",
      "7 0.7147711607501194 0.817057280923489 0.08286690898056512\n",
      "0.7153459746030807 0.6152740778443608\n",
      "8 0.7208181514585069 0.8200637421585606 0.08531784893187541\n",
      "0.7282225532886109 0.6256349356647442\n",
      "9 0.7265661387411492 0.8263637212701354 0.086071255332164\n",
      "0.7255203172818219 0.6343571014696887\n",
      "10 0.7249004494635937 0.8153561949652153 0.0844910239116952\n",
      "0.7062434410420135 0.6510477719315655\n",
      "11 0.720531740212147 0.8195863287243382 0.08130173487926663\n",
      "0.7357182396085711 0.6188163680471392\n",
      "12 0.71544324177805 0.8153981420947257 0.07836123081886985\n",
      "0.7067385200360858 0.6418381332564516\n",
      "13 0.7176298452445122 0.8194067948443219 0.08057130103941258\n",
      "0.7274926812858165 0.6255290823873318\n",
      "14 0.7225677848318075 0.8213752404299622 0.08523061758654543\n",
      "0.7161188989725131 0.6371012507930671\n",
      "working on:  checkpointz\\to_slurm\\rnnattn_latent32\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\rnnattn-128_peptide_latent32_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\rnnattn_latent32\\300_rnnattn-128_peptide.ckpt\n",
      "rnnattn-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7405665741115773 0.8547170116561937 0.08652459627560964\n",
      "0.7439990635874139 0.6673347203852729\n",
      "1 0.7411336018162242 0.8518792048155693 0.08391663710036057\n",
      "0.7458525780087448 0.6683783052610031\n",
      "2 0.7392351550860539 0.8526729990139211 0.08681996114317829\n",
      "0.7456209900527593 0.6480801880772439\n",
      "3 0.7356157004176184 0.8462663263499388 0.08566408735031626\n",
      "0.7353824092108778 0.6655665907253635\n",
      "4 0.7389122751506947 0.851253397847166 0.08738223645086775\n",
      "0.7429350648700248 0.6334016146692603\n",
      "5 0.7480583112734658 0.8611673076340906 0.08635482314393403\n",
      "0.7558917178949909 0.6677533019967394\n",
      "6 0.7417302616142707 0.8558296576168519 0.08651321691416072\n",
      "0.7545299885939898 0.6308537785103037\n",
      "7 0.7413930165422368 0.8546057045065483 0.08764898057824246\n",
      "0.74086393811517 0.6715343952927653\n",
      "8 0.7372120126984124 0.847491251313771 0.08891692063838286\n",
      "0.7430972444989954 0.6430726425130996\n",
      "9 0.7430047813639651 0.8553771604170612 0.08684938228536014\n",
      "0.7415681869352978 0.6684114934510063\n",
      "10 0.7365140871179885 0.8527037854702537 0.08930310755392716\n",
      "0.749910157311529 0.6711288016480568\n",
      "11 0.7417450685209357 0.8531054582115402 0.08713806110126683\n",
      "0.7414085139882773 0.6523808732715812\n",
      "12 0.7386615261427867 0.8572121944293454 0.08657835291557957\n",
      "0.7379315526071746 0.6841240743344568\n",
      "13 0.74180080927337 0.8558110923754558 0.08592787127036854\n",
      "0.7469406838460708 0.6880383655068054\n",
      "14 0.7434503091329546 0.8590774889214239 0.08870327561798722\n",
      "0.7521361364459569 0.6740021309029716\n",
      "working on:  checkpointz\\to_slurm\\rnnattn_latent64\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\rnnattn-128_peptide_latent64_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\rnnattn_latent64\\300_rnnattn-128_peptide.ckpt\n",
      "rnnattn-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.697564345160096 0.8184612190240687 0.08128487710373797\n",
      "0.6753934900918853 0.6556031205233146\n",
      "1 0.6977053223383402 0.8211687744641453 0.08236553727605056\n",
      "0.6807845554630585 0.6442995827077578\n",
      "2 0.7082513667754906 0.8229317248433764 0.08368192758559778\n",
      "0.693806322224375 0.6046771631500301\n",
      "3 0.6972410988925826 0.8239529432073005 0.08238477321691812\n",
      "0.6839460977213115 0.6439062190481755\n",
      "4 0.7141675660191887 0.8330023509424129 0.08929176118138356\n",
      "0.6932805291818075 0.6583846232239128\n",
      "5 0.7043413947745919 0.8237905405838201 0.08335301296967076\n",
      "0.7091215204069946 0.6167732030074482\n",
      "6 0.7009066145095402 0.8245016268987978 0.08278102996485391\n",
      "0.7009185178269268 0.6333791224914846\n",
      "7 0.711798069166602 0.8310450428045631 0.0914817533293262\n",
      "0.7110419275620058 0.6150536215168163\n",
      "8 0.7006795647544428 0.8251887929277338 0.08504872206575279\n",
      "0.6973666527943648 0.6267509056576858\n",
      "9 0.7045386861949973 0.8201901282638283 0.0869638706180762\n",
      "0.6855736027706426 0.6355685010973016\n",
      "10 0.702775921360265 0.8201973572858489 0.08363287695999892\n",
      "0.6679508553845115 0.6413258382466606\n",
      "11 0.7006377685576828 0.8200544733761465 0.08339368333272527\n",
      "0.6878107338124315 0.6269161811959598\n",
      "12 0.7037221246672015 0.8224030576107411 0.07970527637231979\n",
      "0.6810201389573062 0.6187670598294976\n",
      "13 0.6989386195329724 0.8223464398703699 0.08264969968112207\n",
      "0.6776939404305321 0.6299708221704929\n",
      "14 0.6966525798858121 0.8218807452209024 0.08069113459014905\n",
      "0.6834074946364003 0.6519026372469248\n",
      "working on:  checkpointz\\to_slurm\\rnn_latent128\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\rnn-128_peptide_latent128_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\rnn_latent128\\300_rnn-128_peptide.ckpt\n",
      "rnn-128_peptide\n",
      "0 0.7222333274543341 0.7994080797475261 0.06963183352214741\n",
      "0.7208532144052537 0.6228587018867962\n",
      "1 0.7245498873973817 0.8026595634725082 0.07258291009465476\n",
      "0.7131905500160167 0.6240764471118803\n",
      "2 0.7306592584991151 0.8027892033743185 0.07390216556973903\n",
      "0.7016020051065505 0.6497260286300095\n",
      "3 0.731203820921777 0.8093423395546505 0.07631758315626826\n",
      "0.7036204349877031 0.6488729711871669\n",
      "4 0.7279739258521366 0.8045157404253067 0.0725616017387771\n",
      "0.7162053586733566 0.6365812753269858\n",
      "5 0.7193731332168893 0.7976267549145257 0.07404083466424362\n",
      "0.7024439303448606 0.6534247270185458\n",
      "6 0.7266228723014313 0.8040680669609649 0.0747063515481165\n",
      "0.7126592220165628 0.6575818162790648\n",
      "7 0.726783407833955 0.8047658362248362 0.07537643420658902\n",
      "0.6966723100304442 0.6414498591226023\n",
      "8 0.7251211518631606 0.804510699888552 0.07283400458805314\n",
      "0.7105384742762135 0.6414040499559343\n",
      "9 0.7180056929878992 0.7978857533310509 0.07021963619692989\n",
      "0.6919923924137118 0.6327062734872331\n",
      "10 0.7362743406445981 0.8113296442991162 0.07744811037211245\n",
      "0.7106280066581179 0.6656450888450502\n",
      "11 0.7332301107148781 0.8039980704499516 0.07494334721510909\n",
      "0.7059406757529458 0.6445319677979505\n",
      "12 0.7261945088131216 0.8022143156609842 0.07053495014116234\n",
      "0.687988428584042 0.6570667028088615\n",
      "13 0.7291400710992605 0.8048208033790751 0.07433799973712871\n",
      "0.7049941726480327 0.6432215486595965\n",
      "14 0.7338344308697388 0.81264922321611 0.0706394072602887\n",
      "0.7046683518339563 0.6580515510349547\n",
      "working on:  checkpointz\\to_slurm\\rnn_latent32\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\rnn-128_peptide_latent32_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\rnn_latent32\\300_rnn-128_peptide.ckpt\n",
      "rnn-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.708400392210324 0.8059705605544805 0.06950534833324987\n",
      "0.6691220100454134 0.6617886130066721\n",
      "1 0.7138050400619746 0.8123337747010818 0.07172130779275648\n",
      "0.7070153200753322 0.6335609692622429\n",
      "2 0.7160682513162931 0.8135613092039862 0.07424164988826107\n",
      "0.6976000899188227 0.6426459884125271\n",
      "3 0.6974899345482417 0.7983152007049472 0.06709202618010586\n",
      "0.6679831953824237 0.6421215218428361\n",
      "4 0.713391035083328 0.8126659835845819 0.0723013519277317\n",
      "0.6869646001476122 0.6594274593238485\n",
      "5 0.7193748403436334 0.8155183541689199 0.07325167534948174\n",
      "0.7001088150731921 0.6639813532806469\n",
      "6 0.7062622382578492 0.8081730641511029 0.07008232254190452\n",
      "0.683854027253144 0.6449378280475575\n",
      "7 0.7215701615905677 0.817491112095817 0.07811094629005735\n",
      "0.683344884860801 0.6797388148146273\n",
      "8 0.7136447087133097 0.8114442162927784 0.06974636147655022\n",
      "0.673581958242468 0.6831890638098764\n",
      "9 0.7127623197268452 0.8108237447551802 0.07595050236376262\n",
      "0.6785141553401268 0.6575150152603562\n",
      "10 0.7094831975201403 0.812994356166774 0.07071175513569504\n",
      "0.7104522163286107 0.6374219594951276\n",
      "11 0.7118476160235717 0.8114223457665413 0.07400405254214798\n",
      "0.681978093447241 0.6681426439283893\n",
      "12 0.7133097578524435 0.8074424056848053 0.06635528551197818\n",
      "0.7064280898587665 0.6010916242872815\n",
      "13 0.7114200345567792 0.8068295287574966 0.07014765333588778\n",
      "0.6834327924829136 0.6539402304378646\n",
      "14 0.7067264448317014 0.8065866213925551 0.07334552506845744\n",
      "0.6727705751850841 0.6867786196436992\n",
      "working on:  checkpointz\\to_slurm\\rnn_latent64\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\rnn-128_peptide_latent64_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\rnn_latent64\\300_rnn-128_peptide.ckpt\n",
      "rnn-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7356806216879841 0.8155200977215661 0.07926854772427655\n",
      "0.7218534167974192 0.6174070472353508\n",
      "1 0.7339385089202347 0.8118391832417055 0.08023902073869847\n",
      "0.7361452257451155 0.6204365041010149\n",
      "2 0.7226742661776646 0.8070614554738199 0.07541599163355465\n",
      "0.6869141586837939 0.656559064208113\n",
      "3 0.741013884747428 0.8194293483991114 0.07948203606704829\n",
      "0.7136660250388838 0.6321590292157182\n",
      "4 0.7294393438805129 0.8140825193079237 0.07328835669930578\n",
      "0.7060784193670095 0.6332113891210593\n",
      "5 0.7318833264246167 0.8128946945880823 0.0734643963886279\n",
      "0.7196598449692242 0.6394058226587174\n",
      "6 0.7280650682195162 0.8116767719380819 0.0752296181782866\n",
      "0.7103894958266679 0.6287415816207127\n",
      "7 0.72656349003559 0.8104788244852267 0.07356975681728559\n",
      "0.7065511552830441 0.6345966976611455\n",
      "8 0.7322455415986654 0.8121930707487109 0.07574373883054372\n",
      "0.7268091211519228 0.6092685416908217\n",
      "9 0.7270638095089191 0.8125216821358695 0.07349190435586302\n",
      "0.7063988207604708 0.6555503019180302\n",
      "10 0.7281423492430141 0.8126120623528313 0.07400037480401628\n",
      "0.7204212728043881 0.6473017875029685\n",
      "11 0.7279805421286932 0.8149445444202083 0.07207029123860337\n",
      "0.7043393571219323 0.6316502637366223\n",
      "12 0.7362107253838929 0.8163229754650918 0.07996154118181392\n",
      "0.7056441000354238 0.6613514944875187\n",
      "13 0.7247781283635779 0.8054140703278357 0.07222685075865486\n",
      "0.7212178307940303 0.6098885203308717\n",
      "14 0.7231468735622215 0.8043152031696033 0.0743541556150975\n",
      "0.6901938999999192 0.6367869381186076\n",
      "working on:  checkpointz\\to_slurm\\trans_latent128\\300_trans1x-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\trans1x-128_peptide_latent128_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\trans_latent128\\300_trans1x-128_peptide.ckpt\n",
      "trans1x-128_peptide\n",
      "0 0.567064887615052 0.6724781265405146 0.026125923180826533\n",
      "0.8431539814395894 0.31107919752224444\n",
      "1 0.5622016680523352 0.6644830599585079 0.02417520833581444\n",
      "0.8600167890362898 0.2950096754098682\n",
      "2 0.5643380740023007 0.6790738911969815 0.024327872696304615\n",
      "0.8429762922230417 0.3118814357008731\n",
      "3 0.5680745207645674 0.6775711420625559 0.025456272838861888\n",
      "0.8605705146859349 0.2638926930808416\n",
      "4 0.5636894361637411 0.6692515198119572 0.02541206164625553\n",
      "0.8851798543975716 0.3011280443718277\n",
      "5 0.5634184680405177 0.6669892520944766 0.027358666092129627\n",
      "0.8416164960460513 0.3258646932134407\n",
      "6 0.565119391883968 0.6699213088702095 0.02625425323568322\n",
      "0.876254932281943 0.31997069561888647\n",
      "7 0.5636741889589582 0.675140711541238 0.02444390688456431\n",
      "0.870811143771997 0.29163122663624486\n",
      "8 0.5587600046377748 0.6558915931069592 0.023951553775695508\n",
      "0.8580630782711949 0.314040532685931\n",
      "9 0.5634926679991621 0.6711260517713237 0.02528115949845141\n",
      "0.8306759530475092 0.3404206301114524\n",
      "10 0.5657430299224154 0.6572325023440815 0.027292572731323454\n",
      "0.8791361743547778 0.3003172564576444\n",
      "11 0.5614882499708754 0.6756453788264875 0.02101896596013693\n",
      "0.8586563573847669 0.2976760297300718\n",
      "12 0.5678722739215755 0.6652991619104428 0.026039777882217643\n",
      "0.9030849575082047 0.2836797571450673\n",
      "13 0.5671438578172224 0.672556987533253 0.023035908607962223\n",
      "0.8768733476059303 0.2909353533791743\n",
      "14 0.5628505275081601 0.6567927825154763 0.023537460669948874\n",
      "0.8733543221249189 0.264462225205387\n",
      "working on:  checkpointz\\to_slurm\\trans_latent32\\300_trans1x-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\trans1x-128_peptide_latent32_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\trans_latent32\\300_trans1x-128_peptide.ckpt\n",
      "trans1x-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6279676592154482 0.7418066013289508 0.03972626959525353\n",
      "0.7091970731148862 0.4505130113080097\n",
      "1 0.6355856940583283 0.750303779596559 0.040874522306618304\n",
      "0.7054556482481888 0.45839702977309904\n",
      "2 0.6303125206363556 0.7410625188794165 0.03958254416198772\n",
      "0.6941897896413665 0.4838633285278713\n",
      "3 0.635026817122344 0.7435440408624046 0.04486863522508782\n",
      "0.6899267679452118 0.5014598681717028\n",
      "4 0.6351408942192837 0.7426021829733942 0.04189149541313148\n",
      "0.6979067232986067 0.47369361122205\n",
      "5 0.6337368980389884 0.741772736925402 0.04468909902356348\n",
      "0.7140352031280046 0.4778595695975013\n",
      "6 0.6324333232941465 0.7446888282661192 0.0379346321308823\n",
      "0.6868128272637091 0.4785809058803451\n",
      "7 0.6239969699662881 0.7375489717681447 0.038831237709536795\n",
      "0.7076031647207681 0.4521245183470295\n",
      "8 0.6363238666758324 0.7438037783140634 0.04087603773761205\n",
      "0.6922764442575549 0.506170910989689\n",
      "9 0.6403951600968597 0.7539582988738962 0.04294281593772572\n",
      "0.7037112801340442 0.48700150207593196\n",
      "10 0.6312578625823061 0.7401872116076319 0.0381385401691101\n",
      "0.7013041841137337 0.47311447710685184\n",
      "11 0.6320249068631828 0.744944414109243 0.04488741952812975\n",
      "0.698061030547948 0.4993070286078992\n",
      "12 0.6327315736688433 0.7415991768842578 0.04223526491831216\n",
      "0.7051519821338461 0.49219670969280926\n",
      "13 0.6305050809624242 0.7427963139101489 0.03889672294772055\n",
      "0.6898917728166505 0.47419451673297186\n",
      "14 0.6308677851702035 0.74035542382944 0.04175927192573103\n",
      "0.6999605375861246 0.4776427877317929\n",
      "working on:  checkpointz\\to_slurm\\trans_latent64\\300_trans1x-128_peptide.ckpt \n",
      "\n",
      "analysis:  model_analyses\\test\\trans1x-128_peptide_latent64_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\trans_latent64\\300_trans1x-128_peptide.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans1x-128_peptide\n",
      "0 0.5966027726482804 0.7195728159349181 0.03227014322019266\n",
      "0.8179721667918127 0.3454234548576871\n",
      "1 0.595199000271664 0.706013112551893 0.03195419782844333\n",
      "0.8287454183065226 0.3249996022905073\n",
      "2 0.5941754050499088 0.7169219499648166 0.035170459936458114\n",
      "0.8146960144711323 0.3416264030395506\n",
      "3 0.5944602443530491 0.7194308394162182 0.03527164113484255\n",
      "0.8068300581264747 0.3531412965106735\n",
      "4 0.5953972394151401 0.7208716886621906 0.03376567580580804\n",
      "0.8137834744465051 0.335457537735632\n",
      "5 0.5992482408110946 0.7265244172634493 0.03148920509533335\n",
      "0.810442540739283 0.35689158841628055\n",
      "6 0.5940719083156549 0.7184141805482833 0.03295034681852812\n",
      "0.8087541433505144 0.3416322321019408\n",
      "7 0.5980428042401201 0.7157531495587661 0.036275760443384514\n",
      "0.8298919722356387 0.32832151035484736\n",
      "8 0.6058090195074087 0.7346388318103605 0.035231961250664134\n",
      "0.8103231831554243 0.317074867083711\n",
      "9 0.593021432622584 0.7186661826796016 0.035144075175675506\n",
      "0.7892825504654313 0.3833824256149371\n",
      "10 0.5974428837719428 0.7110634541894839 0.03405017957380645\n",
      "0.7938925233195104 0.3762616075673497\n",
      "11 0.5998036832406324 0.7236258030434808 0.036169803635762325\n",
      "0.8138107004310038 0.3462918925686669\n",
      "12 0.5952602234437468 0.7218585952869542 0.03241920871507725\n",
      "0.7994780487416766 0.3604628760081947\n",
      "13 0.6008327396632102 0.7228205775301578 0.03213861074558841\n",
      "0.8069759560891926 0.36170530664433753\n",
      "14 0.5953776183767261 0.7219479751252218 0.033622230768775255\n",
      "0.7987407265542645 0.3601796328107225\n",
      "working on:  checkpointz\\to_slurm\\wae_latent128\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "analysis:  model_analyses\\test\\wae-128_peptide_latent128_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\wae_latent128\\300_wae-128_peptide.ckpt\n",
      "wae-128_peptide\n",
      "0 0.6662384215651711 0.7503864979767283 0.060217690989938115\n",
      "0.6226666556241462 0.696251714481943\n",
      "1 0.6684873315299743 0.7579427608852479 0.05668153792625225\n",
      "0.6740255347972686 0.6643435953327816\n",
      "2 0.6658542623977743 0.7543158162863532 0.058242980859005\n",
      "0.6399943156050938 0.68673555434425\n",
      "3 0.662324937914731 0.7485952126653701 0.05591284839514332\n",
      "0.6365005646512414 0.684451069998219\n",
      "4 0.658151961110068 0.749710333012449 0.051970495288210905\n",
      "0.6250284844119967 0.696933224020631\n",
      "5 0.6600025807484603 0.7463861028809893 0.05939024067999454\n",
      "0.6449925377203496 0.6798622204153455\n",
      "6 0.6633531579399229 0.7493190252784024 0.056633985739512886\n",
      "0.6364842904274925 0.6874087976567753\n",
      "7 0.6600738048885478 0.7434880974263047 0.056802770001128496\n",
      "0.6346032994134145 0.6853206526799842\n",
      "8 0.6688281012281345 0.7613319680001926 0.059722123233599475\n",
      "0.6405749044774413 0.7014070497888416\n",
      "9 0.6641927873486787 0.7536241889410399 0.05679684773306197\n",
      "0.6435543261000279 0.6766447960155433\n",
      "10 0.6648471773897567 0.7549474063656598 0.05449067543889216\n",
      "0.6517841314225405 0.6805506515500745\n",
      "11 0.6674679047913181 0.7582084333016512 0.05584692575812516\n",
      "0.6489095658796045 0.6749734591637874\n",
      "12 0.6623746700209273 0.7470617906059408 0.05410569481746063\n",
      "0.627454328826508 0.6974694276522455\n",
      "13 0.6669154054870079 0.7555682748458783 0.060526308240720215\n",
      "0.6443390254472257 0.6862270342677144\n",
      "14 0.671460435338659 0.7573326277586248 0.06117749119203682\n",
      "0.6481913953613684 0.6850294721535941\n",
      "working on:  checkpointz\\to_slurm\\wae_latent32\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "analysis:  model_analyses\\test\\wae-128_peptide_latent32_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\wae_latent32\\300_wae-128_peptide.ckpt\n",
      "wae-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6541345685872626 0.7549236365678704 0.052205489005400785\n",
      "0.5856543675533123 0.7029362566947683\n",
      "1 0.655991009110788 0.7586242595381368 0.05862326849702803\n",
      "0.5831973617128319 0.6770707491105883\n",
      "2 0.6573441672424687 0.7609925085057806 0.05548732589854551\n",
      "0.5981403350526455 0.6942720397319719\n",
      "3 0.6552051530225654 0.7608196232030452 0.05295081572074026\n",
      "0.6055794372226464 0.6663611732071139\n",
      "4 0.6510348861013936 0.7543985991190512 0.053950545617783924\n",
      "0.5821297605523451 0.6910168438755682\n",
      "5 0.6600175149130149 0.7668079502927658 0.05830067549212349\n",
      "0.5915375103654387 0.6935467535866\n",
      "6 0.6536075836659758 0.7587660997558593 0.05411278203996566\n",
      "0.5948609952807199 0.6835871566330081\n",
      "7 0.6446656014918064 0.7522145911793493 0.05157239778607759\n",
      "0.5907502322311464 0.6759952032200476\n",
      "8 0.6571865091921288 0.7661963371381338 0.05689522206640763\n",
      "0.6034923808707724 0.6815690488428783\n",
      "9 0.6534141304083653 0.7583362062546692 0.052777670148148936\n",
      "0.5954506326083666 0.6691297087514501\n",
      "10 0.6542930409023281 0.7604493260095929 0.05395871992836744\n",
      "0.5948846624623412 0.6939651846380339\n",
      "11 0.6525566692387608 0.7578657109261534 0.053060613829523165\n",
      "0.5988054752227435 0.6685782200772032\n",
      "12 0.6515062916653694 0.7569505526645224 0.050701008614288647\n",
      "0.5985369439260707 0.6645979684659575\n",
      "13 0.6507641678863042 0.7519641382790084 0.05192736314153334\n",
      "0.6092552162217264 0.668845413900214\n",
      "14 0.6578093149536177 0.7597530850321168 0.05261533662594413\n",
      "0.594113097870922 0.6610563017766116\n",
      "working on:  checkpointz\\to_slurm\\wae_latent64\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "analysis:  model_analyses\\test\\wae-128_peptide_latent64_test\\saved_info.csv checkpoint:  checkpointz\\to_slurm\\wae_latent64\\300_wae-128_peptide.ckpt\n",
      "wae-128_peptide\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s_renaud\\Documents\\GitHub\\MSCSAM_TBD\\main_model\\transvae\\trans_models.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6551342767368535 0.7538667427934514 0.051001679096075454\n",
      "0.6164872088455731 0.679046885290608\n",
      "1 0.6513444880854253 0.7441023045786026 0.05074253286636861\n",
      "0.6094543703660666 0.6565831776498532\n",
      "2 0.6588813726872794 0.7596153574321425 0.05647510352723941\n",
      "0.634184205358012 0.6382421336072017\n",
      "3 0.6523129120774876 0.7535303754945317 0.05192417004008141\n",
      "0.617148950787217 0.68201425012028\n",
      "4 0.6552013762458554 0.7480821612852226 0.05412370909161562\n",
      "0.6175011555032831 0.670180726842782\n",
      "5 0.6614653540057287 0.7606099481164204 0.05260256326660832\n",
      "0.6209067886275036 0.6623382936235109\n",
      "6 0.654968010770354 0.7486652994597671 0.05403519228837738\n",
      "0.6233097897246873 0.6665387018964359\n",
      "7 0.6627364635969695 0.7548471317827695 0.05323885083039715\n",
      "0.6243743573333378 0.6361219546710919\n",
      "8 0.6585002824740247 0.7572639623825357 0.05781606434228974\n",
      "0.6268826124979592 0.6649781958527057\n",
      "9 0.6439538284902281 0.7408303633831403 0.05006756870296173\n",
      "0.6162696280012866 0.6504025692866411\n",
      "10 0.6511034693420927 0.7487778646912701 0.05123482667047465\n",
      "0.6467383592073994 0.6235218122953199\n",
      "11 0.6584357746962184 0.7578499272906752 0.05668104653919936\n",
      "0.6486383809307567 0.6379749958490617\n",
      "12 0.6618805140631451 0.7559117118159686 0.053129293222504266\n",
      "0.6262669621458832 0.6635735320577328\n",
      "13 0.6583207127758497 0.7526800884819312 0.05442117325871955\n",
      "0.6145370650566592 0.6584036153916881\n",
      "14 0.6556597938610924 0.7493985561104226 0.05026785285051171\n",
      "0.6270864163395147 0.6418087501637555\n"
     ]
    }
   ],
   "source": [
    "import coranking #coranking.readthedocs.io\n",
    "from coranking.metrics import trustworthiness, continuity, LCMC\n",
    "from transvae.snc import SNC #github.com/hj-n/steadiness-cohesiveness\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from transvae import trans_models\n",
    "from transvae.transformer_models import TransVAE\n",
    "from transvae.rnn_models import RNN, RNNAttn\n",
    "from transvae.wae_models import WAE\n",
    "from transvae.aae_models import AAE\n",
    "from transvae.tvae_util import *\n",
    "from transvae import analysis\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "gpu = True\n",
    "\n",
    "example_data = 'data\\\\peptides\\\\datasets\\\\uniprot_v2\\\\peptide_test.txt'\n",
    "test_train='test'\n",
    "ckpt_list = glob.glob(\"\"+\"checkpointz\\\\to_slurm//**//*.ckpt\", recursive = True) #grab all checkpoints\n",
    "analyses_list = glob.glob(\"model_analyses\\\\test//**/*.csv\", recursive=True) #grab all analyses\n",
    "print('current working directory: ',os.getcwd())\n",
    "\n",
    "for i in range(len(ckpt_list)):\n",
    "    \n",
    "    #search the current directory for the model name and load that model\n",
    "    model_dic = {'trans':'TransVAE','aae':'AAE','rnnattn':'RNNAttn','rnn':'RNN','wae':'WAE'}\n",
    "    model_src = ckpt_list[i]\n",
    "    print('working on: ',model_src,'\\n')\n",
    "    model_name = list(filter(None,[key for key in model_dic.keys() if key in model_src.split('//')[-1]]))\n",
    "    model = locals()[model_dic[model_name[0]]](load_fn=model_src) #use locals to call model specific constructor\n",
    "    \n",
    "    #load the analysis file corresponding to the model from the CC outputs\n",
    "    for idx in range(len(analyses_list)):\n",
    "        if analyses_list[idx].split(\"\\\\\")[-2].find(model_src.split(\"\\\\\")[-2].split(\"_\")[0]) != -1 and analyses_list[idx].split(\"\\\\\")[-2].find(model_src.split(\"\\\\\")[-2].split(\"_\")[1]) != -1:\n",
    "            if analyses_list[idx].find(\"rnnattn\")  != -1 and model_src.find(\"rnnattn\") == -1: continue\n",
    "            save_dir = analyses_list[idx]\n",
    "            cur_analysis = pd.read_csv(save_dir)\n",
    "    print(\"analysis: \",save_dir, \"checkpoint: \",model_src)\n",
    "    save_df = cur_analysis #this will hold the number variables and save to CSV\n",
    "    \n",
    "    #load the true labels\n",
    "    data = pd.read_csv(example_data).to_numpy() \n",
    "    data_1D = data[:,0] #gets rid of extra dimension\n",
    "    \n",
    "    #moving into memory and entropy\n",
    "    if model.model_type =='aae':\n",
    "        mus, _, _ = model.calc_mems(data[:60_000], log=False, save=False) \n",
    "    elif model.model_type == 'wae':\n",
    "        mus, _, _ = model.calc_mems(data[:60_000], log=False, save=False) \n",
    "    else:\n",
    "        mems, mus, logvars = model.calc_mems(data[:60_000], log=False, save=False) #subset size 1200*35=42000 would be ok\n",
    "\n",
    "    #create random index and re-index ordered memory list creating n random sub-lists (ideally resulting in IID random lists)\n",
    "    random_idx = np.random.permutation(np.arange(stop=mus.shape[0]))\n",
    "    mus[:] = mus[random_idx]\n",
    "    data = data[random_idx]\n",
    "    \n",
    "    #need to perform PCA to be able to compare dimensionality reduction quality\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_batch =pca.fit_transform(X=mus[:])\n",
    "    \n",
    "    #now ready to calculation dimensionality reduction accuracy with metrics\n",
    "    trust_subsamples = []\n",
    "    cont_subsamples = []\n",
    "    lcmc_subsamples = []\n",
    "    steadiness_subsamples = []\n",
    "    cohesiveness_subsamples = []\n",
    "    if 'test' in test_train: #different number of bootsraps for train vs test\n",
    "        n=15\n",
    "    else:\n",
    "        n=15\n",
    "    parameter = { \"k\": 50,\"alpha\": 0.1 } #for steadiness and cohesiveness\n",
    "    for s in range(n):\n",
    "        s_len = len(mus)//n\n",
    "        Q = coranking.coranking_matrix(mus[s_len*s:s_len*(s+1)], pca_batch[s_len*s:s_len*(s+1)])\n",
    "        trust_subsamples.append( np.mean(trustworthiness(Q, min_k=1, max_k=50)) )\n",
    "        cont_subsamples.append( np.mean(continuity(Q, min_k=1, max_k=50)) )\n",
    "        lcmc_subsamples.append( np.mean(LCMC(Q, min_k=1, max_k=50)) )\n",
    "        print(s,trust_subsamples[s],cont_subsamples[s],lcmc_subsamples[s])\n",
    "\n",
    "        metrics = SNC(raw=mus[s_len*s:s_len*(s+1)], emb=pca_batch[s_len*s:s_len*(s+1)], iteration=300, dist_parameter=parameter)\n",
    "        metrics.fit() #solve for steadiness and cohesiveness\n",
    "        steadiness_subsamples.append(metrics.steadiness())\n",
    "        cohesiveness_subsamples.append(metrics.cohesiveness())\n",
    "        print(metrics.steadiness(),metrics.cohesiveness())\n",
    "        Q=0 #trying to free RAM\n",
    "        metrics=0\n",
    "        torch.cuda.empty_cache() #free allocated CUDA memory\n",
    "\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_trustworthiness':trust_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_continuity':cont_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_lcmc':lcmc_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_steadiness':steadiness_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_cohesiveness':cohesiveness_subsamples})], axis=1)  \n",
    "    \n",
    "    save_df.to_csv(save_dir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f455bf",
   "metadata": {},
   "source": [
    "<H3> This cell concatenates missing saved_info information (usually not necessary when ran in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e63ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_analyses\\train\\aae-128_peptide_latent128_train\\saved_info.csv\n",
      "model_analyses\\train\\aae-128_peptide_latent32_train\\saved_info.csv\n",
      "model_analyses\\train\\aae-128_peptide_latent64_train\\saved_info.csv\n",
      "model_analyses\\train\\rnn-128_peptide_latent128_train\\saved_info.csv\n",
      "model_analyses\\train\\rnn-128_peptide_latent32_train\\saved_info.csv\n",
      "model_analyses\\train\\rnn-128_peptide_latent64_train\\saved_info.csv\n",
      "model_analyses\\train\\rnnattn-128_peptide_latent128_train\\saved_info.csv\n",
      "model_analyses\\train\\rnnattn-128_peptide_latent32_train\\saved_info.csv\n",
      "model_analyses\\train\\rnnattn-128_peptide_latent64_train\\saved_info.csv\n",
      "model_analyses\\train\\trans1x-128_peptide_latent128_train\\saved_info.csv\n",
      "model_analyses\\train\\trans1x-128_peptide_latent32_train\\saved_info.csv\n",
      "model_analyses\\train\\trans1x-128_peptide_latent64_train\\saved_info.csv\n",
      "model_analyses\\train\\wae-128_peptide_latent128_train\\saved_info.csv\n",
      "model_analyses\\train\\wae-128_peptide_latent32_train\\saved_info.csv\n",
      "model_analyses\\train\\wae-128_peptide_latent64_train\\saved_info.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "analyses_list = glob.glob(\"model_analyses\\\\train//**/*o.csv\", recursive=True) #grab all analyses\n",
    "old_analyses_list = glob.glob(\"model_analyses\\\\old\\\\train//**/*o.csv\", recursive=True)\n",
    "\n",
    "for csv,old_csv in zip(analyses_list,old_analyses_list):\n",
    "    print(csv)\n",
    "    analysis = pd.read_csv(csv)\n",
    "    old_analysis = pd.read_csv(old_csv)\n",
    "    old_analysis = old_analysis.drop(columns=old_analysis.loc[:,'position_accs':'pca_func_silhouette[3,4]'].columns)\n",
    "    new_analysis = pd.concat([analysis,old_analysis], axis=1)\n",
    "    new_analysis.to_csv(csv,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b565230",
   "metadata": {},
   "source": [
    "<H3> This cell runs the python peptides package and finds physicochemical properties of peptide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peptides\n",
    "dict_list=[]\n",
    "for seq in data:\n",
    "    pep = peptides.Peptide(seq[0])\n",
    "    dict_list.append(\n",
    "        {\"aliphatic_index\":pep.aliphatic_index(),\n",
    "     \"boman\":pep.boman(),\n",
    "     \"charge_ph3\":pep.charge(pH=3)/len(seq[0]),\n",
    "     \"charge_ph7\":pep.charge(pH=7)/len(seq[0]),\n",
    "     \"charge_ph9\":pep.charge(pH=11)/len(seq[0]),\n",
    "    \"hydrophobic_moment\":pep.hydrophobic_moment()/len(seq[0]),\n",
    "    \"hydrophobicity\":pep.hydrophobicity(),\n",
    "    \"instability_index\":pep.instability_index(),\n",
    "    \"isoelectric_point\":pep.isoelectric_point(),\n",
    "    \"molecular_weight\":pep.molecular_weight()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf549049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv('data/test_physicochem_props.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8601e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_moms = []\n",
    "for dic in dict_list:\n",
    "    hydro_moms.append(dic['charge_ph9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "628b8eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26f44fd4f10>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hydro_moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa6831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
