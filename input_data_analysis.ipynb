{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e37b3b2",
   "metadata": {},
   "source": [
    "<H2> This notebook compares input data to data generated by some of our trained models and compares the AMP distributions of the input data to the non-AMP distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5207539",
   "metadata": {},
   "source": [
    "<H3> The first section looks at input data distribution vs generated sample distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fa6ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transvae import trans_models\n",
    "from transvae.transformer_models import TransVAE\n",
    "from transvae.rnn_models import RNN, RNNAttn\n",
    "from transvae.wae_models import WAE\n",
    "from transvae.aae_models import AAE\n",
    "from transvae.tvae_util import *\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "gpu = True\n",
    "\n",
    "num_sequences = 500_000\n",
    "batch_size = 500#setting for reconstruction\n",
    "example_data = 'data\\\\peptide_test.txt'\n",
    "save_dir_loc = 'model_analyses\\\\sample\\\\' #folder in which to save outpts\n",
    "save_dir_name = 'train' #appended to identify data: train|test|other|etc...\n",
    "\n",
    "ckpt_list = glob.glob(\"\"+\"checkpointz\\\\to_slurm//**//*.ckpt\", recursive = True) #grab all checkpoint\n",
    "print('current working directory: ',os.getcwd())\n",
    "\n",
    "for i in range(len(ckpt_list)):\n",
    "    #search the current directory for the model name and load that model\n",
    "    model_dic = {'trans':'TransVAE','aae':'AAE','rnnattn':'RNNAttn','rnn':'RNN','wae':'WAE'}\n",
    "    model_src = ckpt_list[i]\n",
    "    print('working on: ',model_src,'\\n')\n",
    "    model_name = list(filter(None,[key for key in model_dic.keys() if key in model_src.split('\\\\')[-1]]))\n",
    "    model = locals()[model_dic[model_name[0]]](load_fn=model_src) #use locals to call model specific constructor\n",
    "    \n",
    "    #create save directory for the current model according to latent space size\n",
    "    latent_size = re.findall('(latent[\\d]{2,3})', model_src)\n",
    "    save_dir= save_dir_loc+model.name+\"_\"+latent_size[0]+\"_\"+save_dir_name\n",
    "    if not os.path.exists(save_dir):os.mkdir(save_dir) \n",
    "    save_dir= save_dir+\"//\" \n",
    "    save_df = pd.DataFrame() #this will hold the number variables and save to CSV\n",
    "    \n",
    "    #load the true labels\n",
    "    data = pd.read_csv(example_data).to_numpy() \n",
    "    data_1D = data[:num_sequences,0] #gets rid of extra dimension\n",
    "    \n",
    "    #moving into latent memory\n",
    "    if model.model_type =='aae':\n",
    "        mus, _, _ = model.calc_mems(data[:65_000], log=False, save=False) #50_000\n",
    "    elif model.model_type == 'wae':\n",
    "        mus, _, _ = model.calc_mems(data[:65_000], log=False, save=False) \n",
    "    else:\n",
    "        mems, mus, logvars = model.calc_mems(data[:65_000], log=False, save=False) #subset size 1200*35=42000 would be ok\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section dealing with sequence generation metrics and bootstrapping from the latent space\n",
    "#first randomly sample points within the latents space\n",
    "rnd_seq_count =5_000\n",
    "rnd_latent_list=[] #generate N latent space vectors\n",
    "\n",
    "mem_var = 1.1\n",
    "mem_mean = np.mean(mus, axis=0)\n",
    "\n",
    "for seq in range(rnd_seq_count):\n",
    "    rnd_latent_list.append(np.random.normal(mem_mean,mem_var).astype(np.float32))\n",
    "\n",
    "model.params['BATCH_SIZE'] = 250\n",
    "rnd_token_list=np.empty((rnd_seq_count,model.tgt_len)) #store N decoded latent vectors now in token(0-20) form max length 125\n",
    "\n",
    "#decode these points into predicted amino acid tokens (integers)\n",
    "for batch in range(0,rnd_seq_count,model.params['BATCH_SIZE']):\n",
    "    rnd_token_list[batch:batch+model.params['BATCH_SIZE']] =  model.greedy_decode(torch.tensor(rnd_latent_list[batch:batch+model.params['BATCH_SIZE']]).cuda()).cpu()\n",
    "\n",
    "#turn the tokens into characters\n",
    "decoded_rnd_seqs = decode_mols(torch.tensor(rnd_token_list), model.params['ORG_DICT'])\n",
    "decoded_rnd_seqs[:]=[x for x in decoded_rnd_seqs if x] #removes the empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peptides\n",
    "dict_list=[]\n",
    "#calculate physicochemical properties of generated sequences\n",
    "for seq in decoded_rnd_seqs:\n",
    "    pep = peptides.Peptide(seq)\n",
    "    dict_list.append(\n",
    "        {\"aliphatic_index\":pep.aliphatic_index(),\n",
    "     \"boman\":pep.boman(),\n",
    "     \"charge_ph3\":pep.charge(pH=3)/len(seq[0]),\n",
    "     \"charge_ph7\":pep.charge(pH=7)/len(seq[0]),\n",
    "     \"charge_ph11\":pep.charge(pH=11)/len(seq[0]),\n",
    "    \"hydrophobicity\":pep.hydrophobicity(),\n",
    "    \"instability_index\":pep.instability_index(),\n",
    "    \"isoelectric_point\":pep.isoelectric_point(),\n",
    "    \"molecular_weight\":pep.molecular_weight()} )\n",
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv('data/sampled_physicochem_props.csv',index=False)\n",
    "sampled_props = pd.read_csv('data\\\\sampled_physicochem_props.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peptides\n",
    "# re-calculate the test set properties as well\n",
    "dict_list=[]\n",
    "for seq in data_1D:\n",
    "    pep = peptides.Peptide(seq)\n",
    "    dict_list.append(\n",
    "        {\"aliphatic_index\":pep.aliphatic_index(),\n",
    "     \"boman\":pep.boman(),\n",
    "     \"charge_ph3\":pep.charge(pH=3)/len(seq[0]),\n",
    "     \"charge_ph7\":pep.charge(pH=7)/len(seq[0]),\n",
    "     \"charge_ph11\":pep.charge(pH=11)/len(seq[0]),\n",
    "    \"hydrophobicity\":pep.hydrophobicity(),\n",
    "    \"instability_index\":pep.instability_index(),\n",
    "    \"isoelectric_point\":pep.isoelectric_point(),\n",
    "    \"molecular_weight\":pep.molecular_weight()} )\n",
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv('data/new_test_physicochem_props.csv',index=False)\n",
    "input_props = pd.read_csv('data\\\\new_test_physicochem_props.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7762a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in input_props.columns:\n",
    "    if col=='hydrophobic_moment':\n",
    "        continue\n",
    "    plt.figure()\n",
    "    bins = np.linspace(min(input_props[col]), max(input_props[col]), 40)\n",
    "    plt.hist(input_props[col],bins=bins, density=True)\n",
    "    plt.hist(sampled_props[col],bins=bins, density=True, alpha=0.6)\n",
    "    plt.title('{}'.format(col))\n",
    "    plt.savefig('distributions\\\\transformer_128_model_{}_distribution.png'.format(col),facecolor='white',transparent=None, dpi=600)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee82233",
   "metadata": {},
   "source": [
    "<h3> Checking AMP | NON-AMP Distributions in the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "gpu = True\n",
    "\n",
    "num_sequences = 500_000\n",
    "batch_size = 500#setting for reconstruction\n",
    "example_data = 'data\\\\peptide_test.txt'\n",
    "save_dir_loc = 'distributions' #folder in which to save outpts\n",
    "true_prop_src = 'data\\\\function_test.txt' #if property predictor load the true labels\n",
    "save_dir_name = 'AMP_NON_AMP' #appended to identify data: train|test|other|etc...\n",
    "\n",
    "# ckpt_list = glob.glob(\"\"+\"checkpointz\\\\to_slurm//**//*.ckpt\", recursive = True) #grab all checkpoint\n",
    "# print('current working directory: ',os.getcwd())\n",
    "\n",
    "save_dir= save_dir_loc+\"_\"+save_dir_name\n",
    "if not os.path.exists(save_dir):os.mkdir(save_dir) \n",
    "save_dir= save_dir+\"//\" \n",
    "\n",
    "#load the true labels\n",
    "data = pd.read_csv(example_data).to_numpy() \n",
    "data_1D = data[:num_sequences,0] #gets rid of extra dimension\n",
    "true_props_data = pd.read_csv(true_prop_src).to_numpy()\n",
    "true_props = true_props_data[0:num_sequences,0]\n",
    "    \n",
    "\n",
    "\n",
    "# for i in range(len(ckpt_list)):\n",
    "#     #search the current directory for the model name and load that model\n",
    "#     model_dic = {'trans':'TransVAE','aae':'AAE','rnnattn':'RNNAttn','rnn':'RNN','wae':'WAE'}\n",
    "#     model_src = ckpt_list[i]\n",
    "#     print('working on: ',model_src,'\\n')\n",
    "#     model_name = list(filter(None,[key for key in model_dic.keys() if key in model_src.split('\\\\')[-1]]))\n",
    "#     model = locals()[model_dic[model_name[0]]](load_fn=model_src) #use locals to call model specific constructor\n",
    "    \n",
    "#     #create save directory for the current model according to latent space size\n",
    "#     latent_size = re.findall('(latent[\\d]{2,3})', model_src)\n",
    "#     save_dir= save_dir_loc+model.name+\"_\"+latent_size[0]+\"_\"+save_dir_name\n",
    "#     if not os.path.exists(save_dir):os.mkdir(save_dir) \n",
    "#     save_dir= save_dir+\"//\" \n",
    "#     save_df = pd.DataFrame() #this will hold the number variables and save to CSV\n",
    "    \n",
    "#     #load the true labels\n",
    "#     data = pd.read_csv(example_data).to_numpy() \n",
    "#     data_1D = data[:num_sequences,0] #gets rid of extra dimension\n",
    "#     true_props_data = pd.read_csv(true_prop_src).to_numpy()\n",
    "#     true_props = true_props_data[0:num_sequences,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c66d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the physico-chemical properties from file: ORDER MUST BE THE SAME AS DATASET ORDER!\n",
    "input_props = pd.read_csv('data\\\\new_test_physicochem_props.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c176bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_property_list=[]\n",
    "non_amp_property_list=[]\n",
    "for idx, amp_check in enumerate(true_props):\n",
    "    if amp_check==1:\n",
    "        amp_property_list.append(input_props.iloc[idx])\n",
    "    else:\n",
    "        non_amp_property_list.append(input_props.iloc[idx])\n",
    "assert len(amp_property_list+non_amp_property_list) == input_props.shape[0] #just check that the split happened correctly\n",
    "amp_property_df = pd.DataFrame(amp_property_list)\n",
    "non_amp_propertly_df = pd.DataFrame(non_amp_property_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in amp_property_df.columns:\n",
    "    if col=='hydrophobic_moment':\n",
    "        continue\n",
    "    plt.figure()\n",
    "    bins = np.linspace(min(input_props[col]), max(input_props[col]), 40)\n",
    "    plt.hist(amp_property_df[col],bins=bins, density=True)\n",
    "    plt.hist(non_amp_propertly_df[col],bins=bins, density=True, alpha=0.6)\n",
    "    plt.title('{}'.format(col))\n",
    "    plt.savefig(save_dir+\"{}.png\".format(col),facecolor='white',transparent=None, dpi=600)\n",
    "    if col=='molecular_weight':\n",
    "        plt.figure()\n",
    "        plt.hist(amp_property_df[col],bins=bins, density=False)\n",
    "        plt.hist(non_amp_propertly_df[col],bins=bins, density=False, alpha=0.6)\n",
    "        plt.title('{}_non_density'.format(col))\n",
    "        plt.savefig(save_dir+\"{}_non_density.png\".format(col),facecolor='white',transparent=None, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22e6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('amp21')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "686011dad3443993f8e7a9bdd4f15acb7c0d9d5c12f48e0b358ae8d8d9013b02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
