{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8307e206",
   "metadata": {},
   "source": [
    "<h3> This notebook will run the total model analysis script and take care of the PCA benchmarks that are run seperately from the aforementioned script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22c7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\amp21\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory:  c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\n",
      "working on:  checkpointz//all_300_ckpts\\aae_latent128\\300_aae-128_peptide.ckpt \n",
      "\n",
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\aae_latent32\\300_aae-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\aae_latent64\\300_aae-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\rnnattn_latent128\\300_rnnattn-128_peptide.ckpt \n",
      "\n",
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\rnnattn_latent32\\300_rnnattn-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\rnnattn_latent64\\300_rnnattn-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\rnn_latent128\\300_rnn-128_peptide.ckpt \n",
      "\n",
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\rnn_latent32\\300_rnn-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\rnn_latent64\\300_rnn-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\trans_latent128\\300_trans1x-128_peptide.ckpt \n",
      "\n",
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\trans_latent32\\300_trans1x-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\trans_latent64\\300_trans1x-128_peptide.ckpt \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\wae_latent128\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n",
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\wae_latent32\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n",
      "working on:  checkpointz//all_300_ckpts\\wae_latent64\\300_wae-128_peptide.ckpt \n",
      "\n",
      "WAE class init called /n\n",
      "WAE class build_model called /n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sam\\Documents\\GitHub\\latent-spaces-amps\\transvae\\trans_models.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.params['CHAR_WEIGHTS'] = torch.tensor(self.params['CHAR_WEIGHTS'], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on PC[0,1]\n",
      "working on PC[0,2]\n",
      "working on PC[0,3]\n",
      "working on PC[0,4]\n",
      "working on PC[1,2]\n",
      "working on PC[1,3]\n",
      "working on PC[1,4]\n",
      "working on PC[2,3]\n",
      "working on PC[2,4]\n",
      "working on PC[3,4]\n"
     ]
    }
   ],
   "source": [
    "%run total_model_analysis.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71ecb8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x284c7c2f160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca_batch[:,best_pc], function, '.')\n",
    "scan_of_pc =np.linspace(start=pca_mean-(4*pca_std), stop=pca_mean+(4*pca_std), num=peptides_to_probe) #scan 1 dim evenly with best PC\n",
    "plt.scatter(scan_of_pc, [0 for item in range(len(scan_of_pc))], c='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc2219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import coranking #coranking.readthedocs.io\n",
    "from coranking.metrics import trustworthiness, continuity, LCMC\n",
    "from transvae.snc import SNC #github.com/hj-n/steadiness-cohesiveness\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from transvae import trans_models\n",
    "from transvae.transformer_models import TransVAE\n",
    "from transvae.rnn_models import RNN, RNNAttn\n",
    "from transvae.wae_models import WAE\n",
    "from transvae.aae_models import AAE\n",
    "from transvae.tvae_util import *\n",
    "from transvae import analysis\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "gpu = True\n",
    "\n",
    "example_data = 'data\\\\peptides\\\\datasets\\\\uniprot_v3\\\\peptide_train.txt'\n",
    "test_train='train'\n",
    "ckpt_list = glob.glob(\"\"+\"checkpointz\\\\to_slurm//**//*.ckpt\", recursive = True) #grab all checkpoints\n",
    "analyses_list = glob.glob(\"model_analyses\\\\train//**/*.csv\", recursive=True) #grab all analyses\n",
    "print('current working directory: ',os.getcwd())\n",
    "\n",
    "for i in range(len(ckpt_list)):\n",
    "    \n",
    "    #search the current directory for the model name and load that model\n",
    "    model_dic = {'trans':'TransVAE','aae':'AAE','rnnattn':'RNNAttn','rnn':'RNN','wae':'WAE'}\n",
    "    model_src = ckpt_list[i]\n",
    "    print('working on: ',model_src,'\\n')\n",
    "    model_name = list(filter(None,[key for key in model_dic.keys() if key in model_src.split('//')[-1]]))\n",
    "    model = locals()[model_dic[model_name[0]]](load_fn=model_src) #use locals to call model specific constructor\n",
    "    \n",
    "    #load the analysis file corresponding to the model from the CC outputs\n",
    "    for idx in range(len(analyses_list)):\n",
    "        if analyses_list[idx].split(\"\\\\\")[-2].find(model_src.split(\"\\\\\")[-2].split(\"_\")[0]) != -1 and analyses_list[idx].split(\"\\\\\")[-2].find(model_src.split(\"\\\\\")[-2].split(\"_\")[1]) != -1:\n",
    "            if analyses_list[idx].find(\"rnnattn\")  != -1 and model_src.find(\"rnnattn\") == -1: continue\n",
    "            save_dir = analyses_list[idx]\n",
    "            cur_analysis = pd.read_csv(save_dir)\n",
    "    print(\"analysis: \",save_dir, \"checkpoint: \",model_src)\n",
    "    save_df = cur_analysis #this will hold the number variables and save to CSV\n",
    "    \n",
    "    #load the true labels\n",
    "    data = pd.read_csv(example_data).to_numpy() \n",
    "    data_1D = data[:,0] #gets rid of extra dimension\n",
    "    \n",
    "    #moving into memory and entropy\n",
    "    if model.model_type =='aae':\n",
    "        mus, _, _ = model.calc_mems(data[:65_000], log=False, save=False) \n",
    "    elif model.model_type == 'wae':\n",
    "        mus, _, _ = model.calc_mems(data[:65_000], log=False, save=False) \n",
    "    else:\n",
    "        mems, mus, logvars = model.calc_mems(data[:65_000], log=False, save=False) #subset size 1200*35=42000 would be ok\n",
    "\n",
    "    #create random index and re-index ordered memory list creating n random sub-lists (ideally resulting in IID random lists)\n",
    "    random_idx = np.random.permutation(np.arange(stop=mus.shape[0]))\n",
    "    mus[:] = mus[random_idx]\n",
    "    data = data[random_idx]\n",
    "    mus = mus[:30_000]#limit the quantity of data to speed up\n",
    "    data = data[:30_000]\n",
    "    \n",
    "    #need to perform PCA to be able to compare dimensionality reduction quality\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_batch =pca.fit_transform(X=mus) \n",
    "    \n",
    "    #now ready to calculation dimensionality reduction accuracy with metrics\n",
    "    trust_subsamples = []\n",
    "    cont_subsamples = []\n",
    "    lcmc_subsamples = []\n",
    "    steadiness_subsamples = []\n",
    "    cohesiveness_subsamples = []\n",
    "    if 'test' in test_train: #different number of bootsraps for train vs test\n",
    "        n=15\n",
    "    else:\n",
    "        n=15\n",
    "    parameter = { \"k\": 50,\"alpha\": 0.1 } #for steadiness and cohesiveness\n",
    "    for s in range(n):\n",
    "        s_len = len(mus)//n\n",
    "        Q = coranking.coranking_matrix(mus[s_len*s:s_len*(s+1)], pca_batch[s_len*s:s_len*(s+1)])\n",
    "        trust_subsamples.append( np.mean(trustworthiness(Q, min_k=1, max_k=50)) )\n",
    "        cont_subsamples.append( np.mean(continuity(Q, min_k=1, max_k=50)) )\n",
    "        lcmc_subsamples.append( np.mean(LCMC(Q, min_k=1, max_k=50)) )\n",
    "        print(s,trust_subsamples[s],cont_subsamples[s],lcmc_subsamples[s])\n",
    "\n",
    "        metrics = SNC(raw=mus[s_len*s:s_len*(s+1)], emb=pca_batch[s_len*s:s_len*(s+1)], iteration=300, dist_parameter=parameter)\n",
    "        metrics.fit() #solve for steadiness and cohesiveness\n",
    "        steadiness_subsamples.append(metrics.steadiness())\n",
    "        cohesiveness_subsamples.append(metrics.cohesiveness())\n",
    "        print(metrics.steadiness(),metrics.cohesiveness())\n",
    "        Q=0 #trying to free RAM\n",
    "        metrics=0\n",
    "        torch.cuda.empty_cache() #free allocated CUDA memory\n",
    "\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_trustworthiness':trust_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_continuity':cont_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_lcmc':lcmc_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_steadiness':steadiness_subsamples})], axis=1)\n",
    "    save_df = pd.concat([save_df,pd.DataFrame({'latent_to_PCA_cohesiveness':cohesiveness_subsamples})], axis=1)  \n",
    "    \n",
    "    save_df.to_csv(save_dir, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f455bf",
   "metadata": {},
   "source": [
    "<H3> This cell concatenates missing saved_info information (usually not necessary when ran in order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e63ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "analyses_list = glob.glob(\"model_analyses\\\\test//**/*o.csv\", recursive=True) #grab all analyses\n",
    "old_analyses_list = glob.glob(\"model_analyses\\\\old\\\\test//**/*o.csv\", recursive=True)\n",
    "\n",
    "for csv,old_csv in zip(analyses_list,old_analyses_list):\n",
    "    print(csv)\n",
    "    analysis = pd.read_csv(csv)\n",
    "    old_analysis = pd.read_csv(old_csv)\n",
    "    old_analysis = old_analysis.drop(columns=old_analysis.loc[:,'mu_entropies':'latent_to_PCA_cohesiveness'].columns)\n",
    "    new_analysis = pd.concat([old_analysis,analysis], axis=1)\n",
    "    new_analysis.to_csv(csv,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b565230",
   "metadata": {},
   "source": [
    "<H3> This cell runs the python peptides package and finds physicochemical properties of peptide sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import peptides\n",
    "dict_list=[]\n",
    "for seq in data:\n",
    "    pep = peptides.Peptide(seq[0])\n",
    "    dict_list.append(\n",
    "        {\"aliphatic_index\":pep.aliphatic_index(),\n",
    "     \"boman\":pep.boman(),\n",
    "     \"charge_ph3\":pep.charge(pH=3)/len(seq[0]),\n",
    "     \"charge_ph7\":pep.charge(pH=7)/len(seq[0]),\n",
    "     \"charge_ph11\":pep.charge(pH=11)/len(seq[0]),\n",
    "    \"hydrophobic_moment\":pep.hydrophobic_moment()/len(seq[0]),\n",
    "    \"hydrophobicity\":pep.hydrophobicity(),\n",
    "    \"instability_index\":pep.instability_index(),\n",
    "    \"isoelectric_point\":pep.isoelectric_point(),\n",
    "    \"molecular_weight\":pep.molecular_weight()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf549049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_list)\n",
    "df.to_csv('data/train_physicochem_props.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f50cd9",
   "metadata": {},
   "source": [
    "<H3> Special Extra section to perform particular analysis on select Peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a255adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpu = True\n",
    "\n",
    "num_sequences = 500_000\n",
    "batch_size = 200 #setting for reconstruction\n",
    "example_data = 'data\\\\peptides\\\\datasets\\\\uniprot_v3\\\\peptide_test.txt'\n",
    "save_dir_loc = 'model_analyses\\\\sample\\\\' #folder in which to save outpts\n",
    "save_dir_name = 'test' #appended to identify data: train|test|other|etc...\n",
    "\n",
    "reconstruct=True #True:reconstruct data here; False:load reconstructions from file\n",
    "recon_src = \"checkpointz//analyses_ckpts//\" #directory in which all reconstructions are stored\n",
    "true_prop_src = 'data\\\\peptides\\\\datasets\\\\uniprot_v3\\\\function_test.txt' #if property predictor load the true labels\n",
    "subset_src = \"\" #(optional) this file should have the true sequences for a subset of the \"example data\" above\n",
    "\n",
    "ckpt_list = glob.glob(\"\"+\"checkpointz\\\\to_slurm//**//*.ckpt\", recursive = True) #grab all checkpoint\n",
    "print('current working directory: ',os.getcwd())\n",
    "\n",
    "\n",
    "for i in range(len(ckpt_list)):\n",
    "    #search the current directory for the model name and load that model\n",
    "    model_dic = {'trans':'TransVAE','aae':'AAE','rnnattn':'RNNAttn','rnn':'RNN','wae':'WAE'}\n",
    "    model_src = ckpt_list[i]\n",
    "    print('working on: ',model_src,'\\n')\n",
    "    model_name = list(filter(None,[key for key in model_dic.keys() if key in model_src.split('\\\\')[-1]]))\n",
    "    model = locals()[model_dic[model_name[0]]](load_fn=model_src) #use locals to call model specific constructor\n",
    "    \n",
    "    #create save directory for the current model according to latent space size\n",
    "    latent_size = re.findall('(latent[\\d]{2,3})', model_src)\n",
    "    save_dir= save_dir_loc+model.name+\"_\"+latent_size[0]+\"_\"+save_dir_name\n",
    "    if not os.path.exists(save_dir):os.mkdir(save_dir) \n",
    "    save_dir= save_dir+\"//\" \n",
    "    \n",
    "     #load the true labels\n",
    "    data = pd.read_csv(example_data).to_numpy() \n",
    "    data_1D = data[:num_sequences,0] #gets rid of extra dimension\n",
    "    true_props_data = pd.read_csv(true_prop_src).to_numpy()\n",
    "    true_props = true_props_data[0:num_sequences,0]\n",
    "    \n",
    "    ##moving into memory and entropy\n",
    "    if model.model_type =='aae':\n",
    "        mus, _, _ = model.calc_mems(data[:65_000], log=False, save=False) #50_000\n",
    "    elif model.model_type == 'wae':\n",
    "        mus, _, _ = model.calc_mems(data[:65_000], log=False, save=False) \n",
    "    else:\n",
    "        mems, mus, logvars = model.calc_mems(data[:65_000], log=False, save=False) #subset size 1200*35=42000 would be ok\n",
    "    #create random index and re-index ordered memory list\n",
    "    random_idx = np.random.permutation(np.arange(stop=mus.shape[0]))\n",
    "    mus = mus[random_idx]\n",
    "    shuf_data = data[random_idx]\n",
    "\n",
    "    subsample_start=0\n",
    "    subsample_length=mus.shape[0] #mus shape depends on batch size!\n",
    "\n",
    "    #(for length based coloring): record all peptide lengths iterating through input\n",
    "    pep_lengths = []\n",
    "    for idx, pep in enumerate(shuf_data[subsample_start:(subsample_start+subsample_length)]):\n",
    "        pep_lengths.append( len(pep[0]) )   \n",
    "    #(for function based coloring): pull function from csv with peptide functions\n",
    "    s_to_f =pd.read_csv(true_prop_src)    \n",
    "    function = s_to_f['peptides'][subsample_start:(subsample_start+subsample_length)]\n",
    "    function = function[random_idx] #account for random permutation\n",
    "\n",
    "    pca = PCA(n_components=5,svd_solver='full')\n",
    "    pca_batch =pca.fit_transform(X=mus[:])\n",
    "    \n",
    "    #list of AMPs of interest\n",
    "    probing_amps=np.array(('GKIIKLKASLKLL','GAIIKLKASLKLL','GKIIKLAASLKLL','GKIIKLKASLALL',\n",
    "                           'GKIIKLKAALALL','GKIIALKASLKLL','IGIKLLKSKLKAL'))\n",
    "    probing_amps=np.reshape(probing_amps,(len(probing_amps),1))\n",
    "    \n",
    "    model.params['BATCH_SIZE'] = 7\n",
    "    if model.model_type =='aae' or model.model_type =='wae':\n",
    "        probed_mus,_,_=model.calc_mems(probing_amps,log=False,save=False)\n",
    "    else:\n",
    "        _,probed_mus,_=model.calc_mems(probing_amps,log=False,save=False)\n",
    "    reduced_amp_probes=pca.transform(X=probed_mus[:])\n",
    "    \n",
    "    #plotting\n",
    "    titles={'text':'{}'.format(model.model_type.replace(\"_\",\" \").upper()),\n",
    "            'x':0.5,'xanchor':'center','yanchor':'top','font_size':40}\n",
    "    general_fonts={'family':\"Helvetica\",'size':30,'color':\"Black\"}\n",
    "    colorbar_fmt={'title_font_size':30,'thickness':15,'ticks':'','title_text':'Lengths',\n",
    "                  'ticklabelposition':\"outside bottom\"}\n",
    "    \n",
    "    #need to add the probed amps to the data\n",
    "    converted_function = list(map(lambda itm: \"AMP\" if itm==1 else \"NON-AMP\",function))\n",
    "    function_w_probe_amps = np.append(converted_function, probing_amps.flatten(),axis=0)\n",
    "    pca_w_probe_amps = np.append(pca_batch,reduced_amp_probes, axis=0)\n",
    "    \n",
    "    fig = px.scatter_matrix(pd.DataFrame({\"PC1\":pca_w_probe_amps[:,0],\"PC2\":pca_w_probe_amps[:,1],\n",
    "                                            \"PC3\":pca_w_probe_amps[:,2],\"PC4\":pca_w_probe_amps[:,3],\n",
    "                                            \"PC5\":pca_w_probe_amps[:,4],\"Function\":function_w_probe_amps}),\n",
    "                                            dimensions=[\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\"],template='simple_white',\n",
    "                                            color='Function',\n",
    "                                            symbol_sequence=['x-thin','circle',\n",
    "                                                             'square-dot','square-dot','square-dot',\n",
    "                                                             'square-dot','square-dot','square-dot','square-dot'],\n",
    "                                            symbol='Function', opacity=0.8)\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    fig.update_layout(title=titles,font=general_fonts)\n",
    "    fig.write_image(save_dir+'pca_matrix_function.png', width=5_000, height=2500)\n",
    "    \n",
    "    #now we sample near the existing amps\n",
    "    sample_count=10\n",
    "    amp_sample_list=[]\n",
    "    for idx,amp in enumerate(probed_mus):\n",
    "        print(\"working on amp sample number: \",idx)\n",
    "        current_mu=np.expand_dims(amp.astype(np.float32),0)\n",
    "        nearby_samples = np.random.normal(loc=0,scale=1,size=(sample_count,1,model.params['d_latent'])).astype(np.float32)*0.3 + current_mu\n",
    "        model.params['BATCH_SIZE'] = 25\n",
    "        rnd_token_list=np.empty((sample_count,model.tgt_len)) #store N decoded latent vectors now in token(0-20) form max length 125\n",
    "        for batch in range(0,sample_count,model.params['BATCH_SIZE']):\n",
    "            rnd_token_list[batch:batch+model.params['BATCH_SIZE']] =  model.greedy_decode(torch.tensor(nearby_samples[batch:batch+model.params['BATCH_SIZE']]).squeeze().cuda()).cpu()\n",
    "            decoded_rnd_seqs = decode_mols(torch.tensor(rnd_token_list), model.params['ORG_DICT'])\n",
    "        amp_sample_list.append(decoded_rnd_seqs)\n",
    "    with open(save_dir+'amp_sample_list.txt','w') as f:\n",
    "        for amp in amp_sample_list:\n",
    "            f.write(str(amp)+'\\n')\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2cbb468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06204998858223199, 0.026675663716246446)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a short Jaccard similarity test on a list of lists of 20 random letters\n",
    "from transvae.tvae_util import *\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "def random_char(y):\n",
    "    list1=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T']\n",
    "    return ''.join(random.choice(list1) for x in range(y))\n",
    "\n",
    "str_list=[random_char(50) for i in range(200)]\n",
    "str_list\n",
    "np.average(jaccard_similarity_score(str_list,2)), np.std(jaccard_similarity_score(str_list,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e532a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('amp21')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "686011dad3443993f8e7a9bdd4f15acb7c0d9d5c12f48e0b358ae8d8d9013b02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
